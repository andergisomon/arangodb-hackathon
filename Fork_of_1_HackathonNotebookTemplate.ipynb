{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andergisomon/arangodb-hackathon/blob/dev_Ander/Fork_of_1_HackathonNotebookTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set path to query file directory"
      ],
      "metadata": {
        "id": "sFRXio5-Q4Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUERYFILE_FOLDER_PATH = \"/content/queryfile_temp\""
      ],
      "metadata": {
        "id": "jUL0nDCyQ3SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "F9a0zxInVhfT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrF3x-kONUl_"
      },
      "source": [
        "Install ```jedi``` first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0ZhvjqA3NLFN",
        "outputId": "6e87970a-b109-4dac-b7bf-387f67c1c0ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi) (0.8.4)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Collecting pip-tools==6.13.0\n",
            "  Downloading pip_tools-6.13.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting build (from pip-tools==6.13.0)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (8.1.8)\n",
            "Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (24.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (0.45.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build->pip-tools==6.13.0) (24.2)\n",
            "Collecting pyproject_hooks (from build->pip-tools==6.13.0)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pyproject_hooks, build, pip-tools\n",
            "Successfully installed build-1.2.2.post1 pip-tools-6.13.0 pyproject_hooks-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install jedi\n",
        "!pip install pip-tools==6.13.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSZTXz9INmGi"
      },
      "source": [
        "Make a ```requirements.in``` text that has ```nx-arangodb``` in it and upload to ```/content/``` in Colab. Then run the following to generate a dependency list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eqdvab3GMMlW",
        "outputId": "3db00114-10a7-49c6-e5b6-80c30e6696af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m# This file is autogenerated by pip-compile with Python 3.11\u001b[0m\u001b[0m\n",
            "\u001b[32m# by the following command:\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m#    pip-compile /content/requirements.in\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "adbnx-adapter==5.0.6\n",
            "    \u001b[32m# via nx-arangodb\u001b[0m\u001b[0m\n",
            "certifi==2025.1.31\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "charset-normalizer==3.4.1\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "idna==3.10\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "importlib-metadata==8.6.1\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "markdown-it-py==3.0.0\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "mdurl==0.1.2\n",
            "    \u001b[32m# via markdown-it-py\u001b[0m\u001b[0m\n",
            "networkx==3.4\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   nx-arangodb\u001b[0m\u001b[0m\n",
            "numpy==1.26.4\n",
            "    \u001b[32m# via phenolrs\u001b[0m\u001b[0m\n",
            "nx-arangodb==1.3.0\n",
            "    \u001b[32m# via -r /content/requirements.in\u001b[0m\u001b[0m\n",
            "packaging==24.2\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "phenolrs==0.5.9\n",
            "    \u001b[32m# via nx-arangodb\u001b[0m\u001b[0m\n",
            "pygments==2.19.1\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "pyjwt==2.10.1\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "python-arango==8.1.6\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   nx-arangodb\n",
            "    #   phenolrs\u001b[0m\u001b[0m\n",
            "requests==2.32.3\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   python-arango\n",
            "    #   requests-toolbelt\u001b[0m\u001b[0m\n",
            "requests-toolbelt==1.0.0\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "rich==13.9.4\n",
            "    \u001b[32m# via adbnx-adapter\u001b[0m\u001b[0m\n",
            "urllib3==2.3.0\n",
            "    \u001b[32m# via\n",
            "    #   python-arango\n",
            "    #   requests\u001b[0m\u001b[0m\n",
            "zipp==3.21.0\n",
            "    \u001b[32m# via importlib-metadata\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[32m# The following packages are considered to be unsafe in a requirements file:\u001b[0m\u001b[0m\n",
            "\u001b[32m# setuptools\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!echo \"nx-arangodb\" > requirements.in\n",
        "!pip-compile '/content/requirements.in'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0bGp0SrNYYi"
      },
      "source": [
        "Install ```nx-arangodb``` based on the generated ```requirements.txt```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j4XHePCvMfcF",
        "outputId": "f4ff48fb-0724-4d33-801f-9f1300e0f908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nx-arangodb\n",
            "  Downloading nx_arangodb-1.3.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting adbnx-adapter==5.0.6 (from -r requirements.txt (line 7))\n",
            "  Downloading adbnx_adapter-5.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: certifi==2025.1.31 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: importlib-metadata==8.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (8.6.1)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.0.0)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.1.2)\n",
            "Collecting networkx==3.4 (from -r requirements.txt (line 21))\n",
            "  Downloading networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (1.26.4)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (24.2)\n",
            "Collecting phenolrs==0.5.9 (from -r requirements.txt (line 31))\n",
            "  Downloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting pygments==2.19.1 (from -r requirements.txt (line 33))\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyjwt==2.10.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (2.10.1)\n",
            "Collecting python-arango==8.1.6 (from -r requirements.txt (line 37))\n",
            "  Downloading python_arango-8.1.6-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt==1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (1.0.0)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 49)) (13.9.4)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (2.3.0)\n",
            "Requirement already satisfied: zipp==3.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 55)) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter==5.0.6->-r requirements.txt (line 7)) (75.1.0)\n",
            "Using cached nx_arangodb-1.3.0-py3-none-any.whl (67 kB)\n",
            "Using cached adbnx_adapter-5.0.6-py3-none-any.whl (21 kB)\n",
            "Using cached networkx-3.4-py3-none-any.whl (1.7 MB)\n",
            "Using cached phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached python_arango-8.1.6-py3-none-any.whl (114 kB)\n",
            "Installing collected packages: pygments, networkx, python-arango, phenolrs, adbnx-adapter, nx-arangodb\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adbnx-adapter-5.0.6 networkx-3.4 nx-arangodb-1.3.0 phenolrs-0.5.9 pygments-2.19.1 python-arango-8.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install nx-arangodb -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J48LT4U7icx"
      },
      "source": [
        "Install again if some dependencies are still not resolved:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pV0dx8Ny1q64",
        "outputId": "d2351279-3f96-4fa1-d969-ed10d97a2b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nx-arangodb in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: networkx<=3.4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (3.4)\n",
            "Requirement already satisfied: phenolrs~=0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (0.5.9)\n",
            "Requirement already satisfied: python-arango~=8.1 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (8.1.6)\n",
            "Requirement already satisfied: adbnx-adapter~=5.0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (5.0.6)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Install nx-arangodb via pip\n",
        "# Github: https://github.com/arangodb/nx-arangodb\n",
        "\n",
        "!pip install nx-arangodb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fL49rhZKXRXr",
        "outputId": "b505785e-c11f-4db4-a622-55428b923964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar  2 03:28:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "# 2. Check if you have an NVIDIA GPU\n",
        "# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n",
        "\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SITrT75LXRXr",
        "outputId": "66fb8758-fda0-42ba-c86a-4d2b55e0f4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: nx-cugraph-cu12 in /usr/local/lib/python3.11/dist-packages (24.12.0)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (13.3.0)\n",
            "Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (3.4)\n",
            "Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (1.26.4)\n",
            "Requirement already satisfied: pylibcugraph-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (10.3.6.82)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.1.3)\n",
            "Requirement already satisfied: pylibraft-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: rmm-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.1)\n",
            "Requirement already satisfied: cuda-python<13.0a0,<=12.6.0,>=12.0 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.6.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.61.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.82)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.44.0)\n"
          ]
        }
      ],
      "source": [
        "# 3. Install nx-cugraph via pip\n",
        "# Note: Only enable this installation if the step above is working!\n",
        "\n",
        "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yg4VdzwmXRXr",
        "outputId": "2866253b-364d-4d02-a6dc-6d3295752a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.40)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.3.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.18 langgraph-0.3.2 langgraph-checkpoint-2.0.16 langgraph-prebuilt-0.1.1 langgraph-sdk-0.1.53 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.40)\n",
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.2.7-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
            "Downloading langchain_mistralai-0.2.7-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: langchain-mistralai\n",
            "Successfully installed langchain-mistralai-0.2.7\n"
          ]
        }
      ],
      "source": [
        "# 4. Install LangChain & LangGraph\n",
        "\n",
        "# !pip install --upgrade langchain langchain-community langchain-openai langgraph\n",
        "!pip install --upgrade langchain langchain-community langgraph\n",
        "!pip install -U langchain-core langchain-mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Locale issue might affect some Colab users\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "md0OBMeDYzvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "XsvDwYI4Vjp8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzIg-a9qXRXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14996195-f58a-409a-c10e-4653df8bbc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[12:47:51 +0000] [INFO]: NetworkX-cuGraph is available.\n",
            "INFO:nx_arangodb:NetworkX-cuGraph is available.\n"
          ]
        }
      ],
      "source": [
        "# 5. Import the required modules\n",
        "\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "\n",
        "from arango import ArangoClient\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "#from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Extra imports\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.tools.structured import StructuredTool\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "\n",
        "from arango import ArangoClient, exceptions # For AQL execution error handling\n",
        "\n",
        "import zipfile\n",
        "from datetime import datetime, timezone # For query_history csv filenaming\n",
        "from typing import Dict, List # To specify edge_attr input in tools are edge attribute dictionaries\n",
        "import itertools as it # Used in tools for plotting graphs\n",
        "import time # To delay calls to LLM, prevent 429s from messing up the inference\n",
        "import sys # To pipe stdout into a log\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database and dataset setup"
      ],
      "metadata": {
        "id": "QCWJwfdBVmn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSmKzDgiXRXr",
        "outputId": "eae4e4d3-43f0-46a6-c4c4-3d3a79e3cd21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<StandardDatabase _system>\n"
          ]
        }
      ],
      "source": [
        "# 6. Connect to the ArangoDB database\n",
        "\n",
        "db = ArangoClient(hosts=\"https://fc54bbcbe286.arangodb.cloud:8529\").db(username=\"root\", password=\"OS0pStxrZG0wk7hVhzUW\", verify=True)\n",
        "\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J-tuJYczXRXs",
        "outputId": "d328d281-d245-4cc7-96a3-371f1a89301b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-03 12:49:07--  https://snap.stanford.edu/data/finefoods.txt.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122104202 (116M) [application/x-gzip]\n",
            "Saving to: ‘finefoods.txt.gz’\n",
            "\n",
            "finefoods.txt.gz    100%[===================>] 116.45M  33.6MB/s    in 5.7s    \n",
            "\n",
            "2025-03-03 12:49:13 (20.5 MB/s) - ‘finefoods.txt.gz’ saved [122104202/122104202]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download dataset\n",
        "!wget https://snap.stanford.edu/data/finefoods.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL5O-wek5N8S"
      },
      "outputs": [],
      "source": [
        "!gunzip finefoods.txt.gz # Unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwikjIgc_3es"
      },
      "outputs": [],
      "source": [
        "def parse_data(file_path): # Function for parsing the dataset\n",
        "       data = []\n",
        "       current_record = {}\n",
        "       with open(file_path, 'r') as file:\n",
        "           for line in file:\n",
        "               line = line.strip()\n",
        "               #print(f\"Current line: {line}\") # Don't run print here. It will mess up Colab\n",
        "               if not line:  # Empty line indicates end of a record\n",
        "                   if current_record:\n",
        "                       data.append(current_record)\n",
        "                       current_record = {}\n",
        "               else:\n",
        "                   # Check if the delimiter is present before splitting\n",
        "                   if ': ' in line:\n",
        "                       key, value = line.split(': ', 1)\n",
        "                       current_record[key] = value\n",
        "                   else:\n",
        "                       # Handle lines without the delimiter (e.g., print or skip)\n",
        "                       print(f\"Skipping delimiterless entry in record: {line}\")\n",
        "\n",
        "                       # or continue to skip the line silently\n",
        "\n",
        "           if current_record:  # Append the last record\n",
        "               data.append(current_record)\n",
        "               print(f\"Record successfully appended: {current_record}\")\n",
        "       return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR5mRxEk2F6L"
      },
      "source": [
        "Clean the dataset. Remove bad bytes and entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMrblsAz8kel"
      },
      "outputs": [],
      "source": [
        "!iconv -f utf-8 -t utf-8 -c finefoods.txt > finefoods_cleaned.txt #sanitize finefoods.txt, some bytes are illegal in UTF-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVkd0h3z67mm",
        "outputId": "4c5d64eb-ac89-4138-d194-a2bc82eaf136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping delimiterless entry in record: 88 years old. ...\n",
            "Skipping delimiterless entry in record: ...creative powers b...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: I am a voracious reader/li...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: ...creative powers b...\n"
          ]
        }
      ],
      "source": [
        "data = parse_data('finefoods_cleaned.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7ws9OYdA8nF"
      },
      "outputs": [],
      "source": [
        "finefoods = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "wH8ZEUu-3FQC",
        "outputId": "cb9fed03-8f2b-4a6d-b18a-677a6d900695"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"finefoods\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"product/productId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"B000634CK0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/userId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A1GF9C98BKZ6C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/profileName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Leeah A. Turner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/helpfulness\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0/0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"3.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1345766400\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"not sure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"i recently got a shih tzu pup and his breeder was feeding him purina pup chow but from what i read the main ingre. should be meat in a pups food so i ordered this and mixed part of her food in with this for a week or so until just feeding him this,he eats it but from hte ingredients it has fillers and biproducts in it so once the 8lb bag gets low i will be ordering some blue buffalo for him to see if he eats it because from what i hear its much better no bi-products or fillers so i will be reviewing that once we transition.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-845357b4-7a9d-4ff8-9709-bfd76a022067\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product/productId</th>\n",
              "      <th>review/userId</th>\n",
              "      <th>review/profileName</th>\n",
              "      <th>review/helpfulness</th>\n",
              "      <th>review/score</th>\n",
              "      <th>review/time</th>\n",
              "      <th>review/summary</th>\n",
              "      <th>review/text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>126349</th>\n",
              "      <td>B000634CK0</td>\n",
              "      <td>A1GF9C98BKZ6C2</td>\n",
              "      <td>Leeah A. Turner</td>\n",
              "      <td>0/0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1345766400</td>\n",
              "      <td>not sure</td>\n",
              "      <td>i recently got a shih tzu pup and his breeder ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-845357b4-7a9d-4ff8-9709-bfd76a022067')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-845357b4-7a9d-4ff8-9709-bfd76a022067 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-845357b4-7a9d-4ff8-9709-bfd76a022067');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       product/productId   review/userId review/profileName  \\\n",
              "126349        B000634CK0  A1GF9C98BKZ6C2    Leeah A. Turner   \n",
              "\n",
              "       review/helpfulness review/score review/time review/summary  \\\n",
              "126349                0/0          3.0  1345766400       not sure   \n",
              "\n",
              "                                              review/text  \n",
              "126349  i recently got a shih tzu pup and his breeder ...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finefoods.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz3fspP1aFSY",
        "outputId": "989a9ec0-7392-414a-9414-785bedf29e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       product/productId   review/userId          review/profileName  \\\n",
            "131100        B0032FKK4Q  A217RHBTO9A4LL  Barbara A. Dagger \"muzzer\"   \n",
            "\n",
            "       review/helpfulness review/score review/time review/summary  \\\n",
            "131100                0/0          5.0  1325203200         mmmmmm   \n",
            "\n",
            "                                              review/text  \n",
            "131100  Not a big fan of milk chocolate but this is gr...  \n"
          ]
        }
      ],
      "source": [
        "an_entry = finefoods[finefoods['review/profileName'].str.contains('Barbara A. Dagger')]\n",
        "\n",
        "print(an_entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU2SmLB9bT5W",
        "outputId": "504f9716-0d4b-430d-f00c-a039d687035d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not a big fan of milk chocolate but this is great!  I will buy again.  I have zero (0) will power.\n"
          ]
        }
      ],
      "source": [
        "print(finefoods[finefoods['review/userId'] == 'A217RHBTO9A4LL']['review/text'][131100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plPeun__3UP8"
      },
      "source": [
        "### Convert finefoods dataframe to NetworkX graph:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq1BDs8U73QV"
      },
      "source": [
        "Define edges using productId and userId as nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnGqBwYO49Kq",
        "outputId": "6101d42f-d965-4ffd-d69e-6a6472f4a910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 330317 nodes and 560804 edges\n"
          ]
        }
      ],
      "source": [
        "# 1. Load the dataset a NetworkX Graph\n",
        "# Reference: https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html\n",
        "\n",
        "G = nx.from_pandas_edgelist(finefoods, \"product/productId\", \"review/userId\", edge_attr=[\"product/productId\", \"review/profileName\", \"review/helpfulness\", \"review/score\", \"review/summary\", \"review/text\"])\n",
        "# theres probably a more elegant way to load the column names as iterable to feed into edge_attr, but this works\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDwAaBcsXRXt"
      },
      "source": [
        "### Persist the Graph in ArangoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "9618d567370f4759a85e715528c0e797",
            "0b6ccce5123b41099c085937f94e79df",
            "f8c73f45f15340d3acc8a12cbdc6bc9e",
            "4d32bc8ccf1c498da44020dd880e3dc9"
          ]
        },
        "collapsed": true,
        "id": "rARNN2aA6QUa",
        "outputId": "1a816999-bb73-45df-b7ee-87b93ddb3973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[12:50:36 +0000] [INFO]: Overwriting graph 'Finefoods'\n",
            "INFO:nx_arangodb:Overwriting graph 'Finefoods'\n",
            "[12:50:36 +0000] [INFO]: Graph 'Finefoods' exists.\n",
            "INFO:nx_arangodb:Graph 'Finefoods' exists.\n",
            "[12:50:36 +0000] [INFO]: Default node type set to 'Finefoods_node'\n",
            "INFO:nx_arangodb:Default node type set to 'Finefoods_node'\n",
            "[2025/03/03 12:50:37 +0000] [625] [INFO] - adbnx_adapter: Instantiated ADBNX_Adapter with database '_system'\n",
            "INFO:adbnx_adapter:Instantiated ADBNX_Adapter with database '_system'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9618d567370f4759a85e715528c0e797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8c73f45f15340d3acc8a12cbdc6bc9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025/03/03 12:51:56 +0000] [625] [INFO] - adbnx_adapter: Created ArangoDB 'Finefoods' Graph\n",
            "INFO:adbnx_adapter:Created ArangoDB 'Finefoods' Graph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph named 'Finefoods' with 330317 nodes and 450001 edges\n"
          ]
        }
      ],
      "source": [
        "G_adb = nxadb.Graph(\n",
        "    name=\"Finefoods\",\n",
        "    db=db,\n",
        "    incoming_graph_data=G,\n",
        "    write_batch_size=10000,\n",
        "    overwrite_graph=True\n",
        ")\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbb4tr628Jzt"
      },
      "source": [
        "Skip here if the Graph is already persisted in ArangoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O3ThlpALI5G9",
        "outputId": "abf3dd24-474a-4708-a023-242561f52061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[12:52:12 +0000] [INFO]: Graph 'Finefoods' exists.\n",
            "INFO:nx_arangodb:Graph 'Finefoods' exists.\n",
            "[12:52:12 +0000] [INFO]: Default node type set to 'Finefoods_node'\n",
            "INFO:nx_arangodb:Default node type set to 'Finefoods_node'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph named 'Finefoods' with 330317 nodes and 560804 edges\n"
          ]
        }
      ],
      "source": [
        "# 2. Re-connect to the same Graph\n",
        "\n",
        "G_adb = nxadb.Graph(name=\"Finefoods\", db=db)\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HWTUKp-_B8K",
        "outputId": "3fbb68ec-668e-48b0-b353-c8f3a64f0abf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_key': '126349', '_id': 'Finefoods_node/126349'}\n"
          ]
        }
      ],
      "source": [
        "print(G_adb.nodes[126349])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgv_6VlpANrH",
        "outputId": "52562d18-1448-4877-8102-91e25dd1b164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(G_adb.has_edge(318552, 318541))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqBp1MzXFVe0",
        "outputId": "1e0a560c-2238-4658-b669-e1eca7224a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_from': 'Finefoods_node/318541', '_id': 'Finefoods_node_to_Finefoods_node/552181', '_key': '552181', '_to': 'Finefoods_node/318552', 'product/productId': 'B001E5E2EK', 'review/helpfulness': '0/0', 'review/profileName': 'ragheed13', 'review/score': '5.0', 'review/summary': 'good quality', 'review/text': \"I ordered this Molasses more than once from Amazon, it's so good and I like it.\"}\n"
          ]
        }
      ],
      "source": [
        "print(G_adb.get_edge_data(318552, 318541))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpFutUC4_rHY"
      },
      "outputs": [],
      "source": [
        "print(type(G_adb.edges['0']['0']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ArangoGraph LangChain wrapper"
      ],
      "metadata": {
        "id": "uuPHgvt2WEtM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHpIFqeYXRX0"
      },
      "outputs": [],
      "source": [
        "# 1. Create the ArangoGraph LangChain wrapper\n",
        "# Reference: https://api.python.langchain.com/en/latest/graphs/langchain_community.graphs.arangodb_graph.ArangoGraph.html\n",
        "\n",
        "arango_graph = ArangoGraph(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate with Mistral API"
      ],
      "metadata": {
        "id": "f8XdiVFUWQvf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4stM5TzT-LSX"
      },
      "source": [
        "We're gonna use models from MistralAI:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCZvx_xfHX5"
      },
      "source": [
        "API Key (Do not delete this): ```A7K3bqlcBkmvNTXHOcA4tgZwfKczavLa```\n",
        "\n",
        "Alt API key: ```1fPG0PvWUZVq3jlTWPkFJvB756ux9f6k```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow9-as89rOfs",
        "outputId": "4f368356-74d2-42db-b561-4c8ffb344c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Mistral API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"MISTRAL_API_KEY\" not in os.environ:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVhd2Tqw8T0_"
      },
      "source": [
        "Verify API key is loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp8fRZNBon_D",
        "outputId": "7e65530c-bbaa-48e1-ae80-68ecbcd6bc8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(\"MISTRAL_API_KEY\" in os.environ)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent tools"
      ],
      "metadata": {
        "id": "1sJAHeFNVKpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for converting natural language to AQL and back to natural language"
      ],
      "metadata": {
        "id": "FqpihkfPUhoD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsJQ3t_HXRX1"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"This tool is available to invoke the\n",
        "    ArangoGraphQAChain object, which enables you to\n",
        "    translate a Natural Language Query into AQL, execute\n",
        "    the query, and translate the result back into Natural Language.\n",
        "    \"\"\"\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "    \tllm=llm,\n",
        "    \tgraph=arango_graph,\n",
        "    \tverbose=True,\n",
        "      allow_dangerous_requests=True,\n",
        "      max_aql_generation_attempts = 4\n",
        "    )\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 5\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            result = chain.invoke(query)\n",
        "        except exceptions.ArangoServerError as e:\n",
        "            attempt = attempt + 1\n",
        "            print(\"Attempt number\", attempt)\n",
        "            print(f\"AQL EXEC ERROR: {e}\")\n",
        "            return f\"AQL EXEC ERROR: {e}\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return str(result[\"result\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for converting natural language to nx algo and back to natural language"
      ],
      "metadata": {
        "id": "Wk7NIJVHUb1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05kgQHvWXRX1"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language (AQL), then do not use\n",
        "    this tool.\n",
        "    When you generate the Python code, only output the executable python code. Do not add the word \"python\" or anything\n",
        "    that might cause the code to return a syntax error.\n",
        "    \"\"\"\n",
        "    ########################\n",
        "\n",
        "    llm_invoke_prompt = f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & concise answer. Avoid setting this variable to a long sequence.\n",
        "    Your code:\n",
        "    \"\"\"\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(llm_invoke_prompt).content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print('-'*10)\n",
        "    print(text_to_nx_cleaned)\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 5\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            text_to_nx_final = llm.invoke(llm_invoke_prompt).content\n",
        "            text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx_final, flags=re.MULTILINE).strip()\n",
        "            print(\"Attempt number\", attempt)\n",
        "            exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        except BaseException as e:\n",
        "            attempt = attempt + 1\n",
        "            print(\"Attempt number\", attempt)\n",
        "            print(f\"EXEC ERROR: {e}\")\n",
        "            return f\"EXEC ERROR: {e}\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print('-'*10)\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"3) Formulating final answer\")\n",
        "\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed the following python code to help me answer my query:\n",
        "\n",
        "        ---\n",
        "        {text_to_nx_final}\n",
        "        ---\n",
        "\n",
        "        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n",
        "\n",
        "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
        "        answer my query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for plotting a single review"
      ],
      "metadata": {
        "id": "vHgFCPbPUV2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwslo8iux23Q"
      },
      "outputs": [],
      "source": [
        "@tool # Commented out for testing\n",
        "def PlotReviewEdge(start_node : int, end_node : int): # Hard-coded tool for generating plot of a single review edge by some user\n",
        "    \"\"\"This tool is available for drawing a NetworkX graph plot of a single edge using nx.draw and matplotlib.\n",
        "    You are responsible for accepting two (2) parameters: the start_node, and the end_node.\n",
        "    You will use this tool to visualize the given start and end nodes, alongside their edge with their attributes,\n",
        "    execute the plot generation code, and finally to return the path to the generated plot image file.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    # Create an empty graph to draw\n",
        "    G = nx.Graph()\n",
        "    product_asin_dict = {}\n",
        "\n",
        "    edge_attr = G_adb.get_edge_data(start_node, end_node, default = False) # Will return False if edge not found, and will return the edge data dict if found\n",
        "\n",
        "    if type(edge_attr) == bool:\n",
        "        raise RuntimeError(f\"edge_attr = {edge_attr}: Edge does not exist\")\n",
        "\n",
        "    product_asin_dict[f\"{int(end_node)}\"] = edge_attr['product/productId']\n",
        "\n",
        "    G.add_edge(start_node, end_node, **edge_attr)\n",
        "    # Generate short summary of the review/text attribute, review/summary attribute is mostly useless\n",
        "    review_text_summary = ShortDescriptionGenerator(review_text = edge_attr.get('review/text'))\n",
        "\n",
        "    G_pos = nx.spring_layout(G)\n",
        "\n",
        "    # Get the edge data for the single edge\n",
        "    edge_data = G.get_edge_data(start_node, end_node)\n",
        "\n",
        "    # Draw the graph with the single edge\n",
        "    nx.draw(G, pos=G_pos, with_labels=True, node_color=\"skyblue\", node_size=200, edge_color=\"skyblue\")\n",
        "\n",
        "    # Generate short summary of the review/text attribute\n",
        "    review_text_summary = ShortDescriptionGenerator(review_text = edge_data.get('review/text'))\n",
        "\n",
        "    # Add linebreaks to review text summary label\n",
        "    words = review_text_summary.split()\n",
        "    result = []\n",
        "    for i in range(0, len(words), 7): # 7 words per line\n",
        "        result.append(\" \".join(words[i : i + 7]))\n",
        "\n",
        "    review_text_summary = \"\\n\".join(result)\n",
        "\n",
        "    # Add edge labels (attributes)\n",
        "    nx.draw_networkx_edge_labels(\n",
        "        G,\n",
        "        pos=G_pos,\n",
        "        font_size=11,\n",
        "        edge_labels={(start_node, end_node): f\"{review_text_summary}\\nUser: {edge_data.get('review/profileName')}\"},\n",
        "        rotate=False)\n",
        "\n",
        "\n",
        "    # nx.draw_networkx_labels(\n",
        "    #     G,\n",
        "    #     pos=G_pos,\n",
        "    #     labels={**user_node_labels, **product_node_labels},\n",
        "    #     font_size=10,\n",
        "    #     bbox={\"alpha\": 0},\n",
        "    #     ax=None,\n",
        "    # )\n",
        "\n",
        "    # Node labels\n",
        "    product_node_labels = {\n",
        "        int(end_node): f\"\\nproductId (ASIN)=\\n{product_asin}\"\n",
        "        for end_node, product_asin in product_asin_dict.items()\n",
        "    }\n",
        "\n",
        "    # user_node_labels = {\n",
        "    #     user_node: f\"profileName={profile_name}\"\n",
        "    #     for user_node, profile_name in G.nodes(data=\"review/profileName\") # data=True return a 2-tuple (node, ddict).\n",
        "    # }\n",
        "\n",
        "    label_pos = {} # Add offset for product node label\n",
        "    for node, (x, y) in G_pos.items():\n",
        "        label_pos[node] = (x + 0.1, y - 0.1)\n",
        "\n",
        "    nx.draw_networkx_labels(\n",
        "        G,\n",
        "        pos=label_pos,\n",
        "        labels=product_node_labels, #{**user_node_labels, **product_node_labels},\n",
        "        font_size=10,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "    )\n",
        "\n",
        "    # Save the plot\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "    plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotReviewEdge_{creation_datetime}.png\"\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return plot_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for plotting multiple reviews from one user"
      ],
      "metadata": {
        "id": "FON_Kp0yU85w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUJ_PbVNcMLI"
      },
      "outputs": [],
      "source": [
        "@tool # Commented out for testing\n",
        "def PlotNReviewEdges(start_node : int, end_nodes_list : List[int]): # Hard-coded tool for generating plot of N review edges made by the same user\n",
        "    \"\"\"This tool is available for drawing a NetworkX graph plot of a multiple edges using nx.draw and matplotlib.\n",
        "    You are responsible for accepting two (2) parameters: the start_node, and the end_nodes_list.\n",
        "    You will use this tool to visualize the given start and end nodes, alongside their edges with their attributes,\n",
        "    execute the plot generation code, and finally to return the path to the generated plot image file.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    # Create an empty graph to draw\n",
        "    G = nx.Graph()\n",
        "    connectionstyle = [f\"arc3,rad={r}\" for r in it.accumulate([0.15] * 8)] # Assuming a user wrote at most 8 reviews\n",
        "    # connectionstyle = [f\"angle3,angleA=90,angleB={r}\" for r in it.accumulate([30] * 8)]\n",
        "\n",
        "    edge_review_text_summary_dict = {}\n",
        "    product_asin_dict = {}\n",
        "\n",
        "    for start_node, end_node in it.product([start_node], end_nodes_list): # Put start_node in a list to make it iterable\n",
        "        edge_attr = G_adb.get_edge_data(start_node, end_node, default = False) # Will return False if edge not found, and will return the edge data dict if found\n",
        "        if type(edge_attr) == bool:\n",
        "            continue # Skip to the next iteration\n",
        "        else:\n",
        "            G.add_edge(start_node, end_node, **edge_attr)\n",
        "\n",
        "            time.sleep(1.2) # Prevent LLM calls that are too fast\n",
        "            # Generate short summary of the review/text attribute, review/summary attribute is mostly useless\n",
        "            review_text_summary = ShortDescriptionGenerator(review_text = edge_attr.get('review/text'))\n",
        "            # review_text_summary = \"\"\n",
        "\n",
        "            # Add linebreaks to review text summary label\n",
        "            words = review_text_summary.split()\n",
        "            result = []\n",
        "            words_per_line = 3 # 3 words per line\n",
        "            for i in range(0, len(words), words_per_line):\n",
        "                result.append(\" \".join(words[i : i + words_per_line]))\n",
        "            review_text_summary = \"\\n\".join(result)\n",
        "\n",
        "            edge_review_text_summary_dict[f\"({int(start_node)}, {int(end_node)})\"] = review_text_summary\n",
        "            product_asin_dict[f\"{int(end_node)}\"] = edge_attr['product/productId']\n",
        "\n",
        "    G_pos = nx.spring_layout(G)\n",
        "    # Draw the graph. pos unspecified defaulting to spring_layout\n",
        "    nx.draw(G, pos=G_pos, with_labels=True, node_color=\"skyblue\", node_size=200, edge_color=\"skyblue\")\n",
        "\n",
        "    edges_attrs_label = {\n",
        "        (start_node, end_node): f\"ASIN={edge_attrs['product/productId']}\\nsummary=\\n{edge_review_text_summary_dict.get(f'({int(start_node)}, {int(end_node)})')}\"\n",
        "        for start_node, end_node, edge_attrs in G.edges(data=True) # data=True return a 3-tuple (u, v, ddict).\n",
        "    }\n",
        "\n",
        "    # Add edge labels (attributes)\n",
        "    nx.draw_networkx_edge_labels(\n",
        "        G,\n",
        "        pos=G_pos,\n",
        "        font_size=8,\n",
        "        edge_labels = edges_attrs_label,\n",
        "        connectionstyle='arc3,rad=0.3',\n",
        "        label_pos=0.6,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "        rotate=False,\n",
        "    )\n",
        "\n",
        "    # Node labels\n",
        "    product_node_labels = {\n",
        "        int(end_node): f\"\\nproductId (ASIN)=\\n{product_asin}\"\n",
        "        for end_node, product_asin in product_asin_dict.items()\n",
        "    }\n",
        "\n",
        "    # user_node_labels = {\n",
        "    #     user_node: f\"profileName={profile_name}\"\n",
        "    #     for user_node, profile_name in G.nodes(data=\"review/profileName\") # data=True return a 2-tuple (node, ddict).\n",
        "    # }\n",
        "\n",
        "    label_pos = {} # Add offset for product node label\n",
        "    for node, (x, y) in G_pos.items():\n",
        "        label_pos[node] = (x + 0.1, y - 0.1)\n",
        "\n",
        "    nx.draw_networkx_labels(\n",
        "        G,\n",
        "        pos=label_pos,\n",
        "        labels=product_node_labels, #{**user_node_labels, **product_node_labels},\n",
        "        font_size=10,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "    )\n",
        "\n",
        "    # Save the plot\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "    plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotNReviewEdges_{creation_datetime}.png\"\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return plot_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function that returns a short description of review"
      ],
      "metadata": {
        "id": "NPjuv48XW7pI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dq4tFxV-bB4"
      },
      "outputs": [],
      "source": [
        "# Since LLM behavior is pretty deterministic when it comes to this task, this won't be a tool but just a simple\n",
        "# function that another tool can call\n",
        "def ShortDescriptionGenerator(review_text : str): # Condense the review/text into a short sentence that can fit in the plot\n",
        "  \"\"\"\n",
        "  This tool is for generating a short but concise description of the review text (review/text).\n",
        "  The description must be one sentence long, with no more than 10 words.\n",
        "\n",
        "  Only use this tool when a review/text is provided.\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"Formulating a short description...\\nReview text: \", review_text)\n",
        "\n",
        "  short_desc = llm.invoke(f\"\"\"\n",
        "  A review text is provided to me. The review text is as follows: {review_text}\n",
        "\n",
        "  Based on the provided review text, generate a short but concise description of the review text.\n",
        "  The description must be one sentence long with no more than 10 words.\n",
        "\n",
        "  Your 10-word-long description:\n",
        "\n",
        "  \"\"\").content\n",
        "\n",
        "  return short_desc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhipP0Pr2Osa"
      },
      "source": [
        "Function to test multiple attempts from errored python code generated by llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJgefmhlNbE3"
      },
      "outputs": [],
      "source": [
        "def test_attempt():\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 3\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            text_to_nx_final = llm.invoke(\"Throw out some nonsense python code that won't run\").content\n",
        "            text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx_final, flags=re.MULTILINE).strip()\n",
        "            print(\"Attempt number\", attempt)\n",
        "            exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        except BaseException as e:\n",
        "            attempt = attempt + 1\n",
        "            print(f\"EXEC ERROR: {e}\")\n",
        "            print(\"Attempt number\", attempt)\n",
        "            return f\"EXEC ERROR: {e}\"\n",
        "            continue\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return text_to_nx_cleaned\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotter tools testing"
      ],
      "metadata": {
        "id": "F8RnmqAtVNoa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buq5OV8VAIMe"
      },
      "source": [
        "### PlotReviewEdge testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "pKiDjZY6AKtV",
        "outputId": "1c7cc327-2961-45aa-8e1d-088831d0802b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formulating a short description...\n",
            "Review text:  I ordered this Molasses more than once from Amazon, it's so good and I like it.\n",
            "Formulating a short description...\n",
            "Review text:  I ordered this Molasses more than once from Amazon, it's so good and I like it.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/queryfile_temp/plots/PlotReviewEdge_2025-03-02T09:32:40.843287+00:00.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "PlotReviewEdge(318552, 318541)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygw3nL0xGZuw"
      },
      "outputs": [],
      "source": [
        "!mkdir {QUERYFILE_FOLDER_PATH}\n",
        "!mkdir {QUERYFILE_FOLDER_PATH}/plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvoarAr0RsrA"
      },
      "source": [
        "### PlotNReviewEdges testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRHrTuXHHEtg"
      },
      "outputs": [],
      "source": [
        "# Sample end_nodes_list for testing\n",
        "test_start_node = 596\n",
        "end_nodes_list = [7390, 8788, 14552, 16252, 16580, 24703, 25693, 31924, 38838, 38869]\n",
        "end_nodes_list_short = [14552, 16580, 38869]\n",
        "end_nodes_list_medium = [14552, 16580, 38869, 16252, 24703]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PlotNReviewEdges(test_start_node, end_nodes_list_medium)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "so3moIs4OVKM",
        "outputId": "c7b142e4-8d73-4eeb-bf69-40e854e337dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formulating a short description...\n",
            "Review text:  Hamburger Helper is a quick fix dinner for our sons (ages 8 and 7) on nights when school activities and/or swimming or judo lessons push our family schedule into the night.<br /><br />Chili Macaroni is one of the five Mexican flavors Hamburger Helper offers. Cheesy Enchilada, Cheesy Nacho, Crunchy Taco and Double Cheese Quesadilla are the others. Each package makes five one-cup servings. Our sons like the Old El Paso seasoning; <a href=\"http://www.amazon.com/gp/product/B001EQ4JEC\">Hamburger Helper Lasagna</a> and <a href=\"http://www.amazon.com/gp/product/B001EQ4IQ6\">Hamburger Helper Beef Pasta</a> are too bland for their tastes. This flavor has just the right amount of spice and seasonings to appeal to the under-10-year-old crowd. The box suggests adding a 4.5 oz. can of Old El Paso chopped green chiles five minutes before the end of the simmer time.<br /><br />A prepared serving (one cup) has 270 calories, 570 mg of sodium and 0.5 g of fat; it also provides a good carb load - 22 grams - and 3 g of protein.<br /><br />Adding the cost of the ground hamburger and vegetables as a side dish, we are able to feed two boys for less than $5 and still have enough leftovers to prepare them a weekend lunch.<br /><br />In summary, while this isn't Haute cuisine, <a href=\"http://www.amazon.com/gp/product/B00434KRHU\">Betty Crocker Hamburger Helper Chili Macaroni</a> is an inexpensive option when pressed for time. For price and convenience, I give the product a five-star rating. For taste, I give it three stars. Again, though, I'm not the target audience, so I'm settling on a four-star rating. The slogan on the box sums it up well, \"One pound. One pan. One tasty meal.\"\n",
            "Formulating a short description...\n",
            "Review text:  <span class=\"tiny\"> Length:: 2:09 Mins<br /><br /></span>My eight-year-old son volunteered to try Nong Shim's new flavor, spicy chicken. I made a video interview of him eating the noodles for dinner, after he came home from judo practice (hungry).<br /><br />Our family enjoys Nong Shim instant noodles. We stock our pantry every autumn with bowls of ramen, yakisoba and udon. Nong Shim is the leading brand of ramyoen (ramen instant noodles) in South Korea.<br /><br />The package design is getting better. The endorsement by Professional Chefs (a 2011 Chef's Best Award) is easier to read and three colored boxes in the lower right corner note that the noodles have no MSG added, there's 30% less sodium than their regular product and that the noodles have 0 grams of trans fat.<br /><br />I recommend adding refrigerator scraps to your instant noodles; perhaps, whole kernel corn (for sweetness) or some tofu, finely chopped green onions (scallions), chopped, cooked beef, chicken or seafood. An egg is another delicious addition.<br /><br />Rating: Five stars.<br /><br />Earlier this year, J. Kenji Lopez-Alt, executive editor at Serious Eats, posted \"Ramen Hacks: 30+ Easy Ways to Upgrade Your Instant Noodles.\" I highly recommend you search out and read the full article because you will never go back to relying on the flavoring packet alone to make instant noodles.<br /><br />I distilled his tips down to these four bullet points:<br /><br />* Simple Add-ins -- Miso paste, chili bean sauce, Thai curry paste, Japanese curry powder, fish sauce, harrisa, vinegar and ponzu.<br /><br />* Vegetation -- Baby spinach, romaine lettuce, bean sprouts, thinly sliced cabbage, watercress, and scallions \"should wilt in a matter of seconds.\"<br /><br />* Eggs -- Hard boiled, soft boiled, the egg-drop method, poached eggs and fried eggs.<br /><br />* Simple Simmered Meat -- Thinly sliced meats cook in a matter of seconds directly in the pot. Chicken breast, pork tenderloin, or flank steak are all great candidates.<br /><br />Instant noodles available at Amazon that our family eats and recommends:<br /><br /><a href=\"http://www.amazon.com/gp/product/B003MOX6RA\">Nong Shim Big Bowl Noodle Udon</a><br /><a href=\"http://www.amazon.com/gp/product/B003MP136A\">Nong Shim Big Bowl Noodle Kimchi</a><br /><a href=\"http://www.amazon.com/gp/product/B00171FB7I\">Nong Shim Beef and Ginger Bowl</a><br /><a href=\"http://www.amazon.com/gp/product/B000LQNK5A\">Nong Shim Kimchi Noodle Bowl</a><br /><a href=\"http://www.amazon.com/gp/product/B0028PDFQG\">Myojo Ippeichan Yakisoba Noodles</a><br /><br />In many cases you can sign up for Amazon's Subscribe & Save program for additional savings and convenience.\n",
            "Formulating a short description...\n",
            "Review text:  My wife likes to start her day with a taste of chocolate, so when Amazon's Subscribe & Save program began offering Chocolate Cheerios at a competitive price we placed an order. The first shipment arrived with an added surprise - each box has a Spongebob Squarepants toy inside! Our sons (ages 8 and 7) happily prepare their mother's morning bowl of cereal, knowing each serving gets them one step closer to completing the 8-piece collection.<br /><br />Of course, my wife would eat Chocolate Cheerios with or without the toy. She eats the cereal with 2% milk and a cup of black coffee because, really, you don't need cream or sugar when you're eating a bowl of chocolate cereal.<br /><br />Getting to the basics: the cereal was tightly packaged with no damage; the expiration date extends at least 12 months out, so there's no mad dash to consume six boxes at once; and the price is competitive with the supermarkets we regularly patronize. The added convenience of the cereal arriving at our doorstep rather than hauling it home in shopping bags is a bonus.<br /><br />Personally, I don't touch the stuff. I'm more of a <a href=\"http://www.amazon.com/gp/product/B002LV6LQS\">Post Raisin Bran Cereal</a> kind of guy. And, yes, of course, we buy that through Amazon's Subscribe & Save program as well.<br /><br />Rating: Five stars\n",
            "Formulating a short description...\n",
            "Review text:  <span class=\"tiny\"> Length:: 1:30 Mins<br /><br /></span>Delicious medium-roast blend with complex tones (5 stars)<br /><br />The name belies an intoxicating medium-roast blend that fuses flavors from Central America, Indonesia and East Africa. The Nantucket Blend is deliciously complex - a m&eacute;lange of four coffees from three continents - opening with the aroma of berries, spice and wine and soft floral undertones and finishing smoky and sweet with a touch of French Roast.<br /><br />According to the Green Mountain Coffee website, the blend's origin dates back more than 20 years ago, \"created at the request of a loyal customer who lived on Nantucket Island. The blend proved a winner, and the name stuck.\"<br /><br />I drink Nantucket Blend black, using Keurig's small mug (7.25 oz) setting. My wife, who will often add creamer to darker roasts, also enjoys this blend black.<br /><br />In summary, this medium-roast blend is a new favorite in our house. We first purchased Nantucket Blend during an Amazon sale for about 55 cents per Keurig cup. Regular price is about 66 cents, 15 cents higher per cup than other brands. Is it worth the additional price? Yes, but keep an eye out for sales.<br /><br />Added bonuses:<br />Nantucket Blend is certified kosher by the Orthodox Union.<br />Green Mountain Coffee is Fair Trade Certified.<br />Green Mountain Coffee is organic.<br /><br />Rating: Five stars.<br /><br />BTW: Here's my recent K-cup coffee reviews for Amazon:<br /><br />5 stars: <a href=\"http://www.amazon.com/gp/product/B004743O08\">Green Mountain Coffee Nantucket Blend</a><br />5 stars: <a href=\"http://www.amazon.com/gp/product/B001CHFUDC\">Coffee People Donut Shop Medium Roast</a><br />5 stars: <a href=\"http://www.amazon.com/gp/product/B0039556K2\">Van Houtte Chocolate Raspberry Truffle</a><br />4 stars: <a href=\"http://www.amazon.com/gp/product/B001EYUE6G\">Green Mountain Coffee Lake & Lodge Blend</a><br />4 stars: <a href=\"http://www.amazon.com/gp/product/B003C4YIFE\">Green Mountain Coffee Vermont Country Blend</a><br />4 stars: Green Mountain Coffee Wild Mountain Blueberry<br />4 stars: <a href=\"http://www.amazon.com/gp/product/B001ELL68Y\">Tully's Coffee Kona Blend</a><br />4 stars: <a href=\"http://www.amazon.com/gp/product/B004779XNW\">Green Mountain Coffee Dark Magic</a><br />3 stars: <a href=\"http://www.amazon.com/gp/product/B003JA5KKS\">Green Mountain Coffee Breakfast Blend</a><br />3 stars: <a href=\"http://www.amazon.com/gp/product/B00390VIQI\">Green Mountain Coffee Fair Trade Gingerbread</a>\n",
            "Formulating a short description...\n",
            "Review text:  Be prepared for visitors. The decadent aroma of Chocolate Raspberry Truffle imbues your kitchen (or office) as you brew this light roast from Van Houtte. We brewed a couple cups at the office (in a cubicle) and the rich aroma carried through the office air vents, attracting droopy-eyed co-workers in search of chocolate.<br /><br />Delicate for a flavored coffee, this blend made a delicious afternoon treat. And, amazingly, the artificial flavoring doesn't leave a strong chemical aftertaste. The smell of rich chocolate and raspberries lingers after the last sip, giving the impression that a team of chocolatiers just departed. Honestly, <a href=\"http://www.amazon.com/gp/product/B0039556K2\">Van Houtte Chocolate Raspberry Truffle</a> is heady stuff.<br /><br />We tested and enjoyed Van Houtte Chocolate Raspberry Truffle both on Keurig's small cup (5.25 oz) and small mug (7.25 oz) settings. According to the Van Houtte website, \"The 8-oz size makes the ideal cup of coffee, but you can vary the cup size if you want to change the coffee's strength (for example, choose a larger cup size to get a less intense cup of coffee).\"<br /><br />If you are concerned about freshness, our box of 24K cups came with an expiration date of July 10, 2011, or more than six months from our purchase date.<br /><br />Rating: Five stars.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/queryfile_temp/plots/PlotNReviewEdges_2025-03-02T09:41:06.591819+00:00.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "1r_vsKAwRl5H",
        "outputId": "28218265-eaa9-402c-82c8-435badd2c31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formulating a short description...\n",
            "Formulating a short description...\n",
            "Formulating a short description...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/queryfile_temp/plots/PlotNReviewEdges_2025-03-02T09:02:43.095857+00:00.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "PlotNReviewEdges(test_start_node, end_nodes_list_short)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PlotNReviewEdges(test_start_node, end_nodes_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "lyWFeH6TGSlF",
        "outputId": "6e1049be-22bf-47aa-9b01-f583b4234a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formulating a short description...\n",
            "Review text:  As part of Amazon's Vine Program I received two trial cans of The Switch, <a href=\"http://www.amazon.com/gp/product/B001LG940E\">Black Cherry</a> and <a href=\"http://www.amazon.com/gp/product/B001LG945O\">Orange Tangerine</a>. I tried both flavors cold (over ice) and rated them 4 stars each, although I prefer the Orange Tangerine flavor to the Black Cherry.<br /><br />Whether or not The Switch is just right or not sweet enough for you will depend on your personal experience with carbonated juice drinks and soda. If you are looking for the sweetness and fizz of a diet soda you will be disappointed. These are 100% juice drinks. The Orange Tangerine flavor has 140 calories and the Black Cherry has 130 calories.<br /><br />I recommend them as an alternative to regular juice to liven up your lunch or help you refuel after a workout. Either way, you are getting 100% of your Vitamin C and there's no added sugar or corn syrup, no preservatives and no artifical colors.<br /><br />The Black Cherry flavor was too mild for me. I was looking for more bite. I could taste hints of the apple, grape and acerola juice concentrates in the blend. The flavor reminded me of blends I've tasted from Treetop. Again, The Switch has a lot less carbonation than you would find in <a href=\"http://www.amazon.com/gp/product/B0014WYXYW\">Izze Fortified All Natural Sparkling Blackberry Juice</a>, for example.<br /><br />The Orange Tangerine flavor should be renamed the Tangerine Orange flavor to reflect the dominate taste and aroma. The Switch's blend is as flavorful as <a href=\"http://www.amazon.com/gp/product/B000BDHBWQ\">essn Sparkling Minneola Tangerine Juice</a> or <a href=\"http://www.amazon.com/gp/product/B001L4EME4\">San Pellegrino Orange</a> although, again, it is no where near as carbonated as those other brands.<br /><br />In summary, these all natural, 100% juice drinks are a healthier option than drinking a soda. The Switch also can help break up the monotony of drinking plain water and/or juice after a workout. Remember to keep them the cans ice cold, though. Preferably, serve them on the rocks.<br /><br />BTW: If you are looking for a full-flavored Black Cherry soda, try <a href=\"http://www.amazon.com/gp/product/B001P9GB4Y\">Thomas Kemper Black Cherry Soda</a>, which has 170 calories per bottle. There's a low calorie (10) version as well but it isn't available on Amazon.\n",
            "Formulating a short description...\n",
            "Review text:  Behind the 12 packets of Via instant coffee, Starbucks placed a brief message, \"Never be without.\" That's a better marketing strategy than, say, \"You could do worse.\" Instant coffee is still instant coffee and no one who starts his or her day with a cup of Joe is about to trade fresh brew or French press for instant.<br /><br />In a pinch, Via is a portable and affordable option.<br /><br />However, I don't recommend Via as a strategy to save money on your coffee bill. A quality coffee press and a thermos will do much better. The 12-packet order currently sells for $8.95 on Amazon, without special offers or subscribe-and-save discounts. That works out to $0.75 per cup, which is about what you'd expect to pay in a standard vending machine. Hands down, Starbucks Via tastes better than anything pouring out of a vending machine. However, each Via stick produces an 8-ounce cup of coffee so, depending which size you normally order, you might spend $1.50 (for 16 ounces) or $2.25 (for 24 ounces).<br /><br />At $0.75 per 8-ounce cup, Starbucks' Via sticks are the same price as SoloBrew's <a href=\"http://www.amazon.com/gp/product/B002QTJ70M\">French Press To-Go SoloPress</a>, which I also reviewed on Amazon.com. I still recommend both brands as tasty and portable options over the ubiquitous, freeze-dried coffee sold in glass jars.<br /><br />Rating: Four stars.\n",
            "Formulating a short description...\n",
            "Review text:  Hamburger Helper is a quick fix dinner for our sons (ages 8 and 7) on nights when school activities and/or swimming or judo lessons push our family schedule into the night.<br /><br />Chili Macaroni is one of the five Mexican flavors Hamburger Helper offers. Cheesy Enchilada, Cheesy Nacho, Crunchy Taco and Double Cheese Quesadilla are the others. Each package makes five one-cup servings. Our sons like the Old El Paso seasoning; <a href=\"http://www.amazon.com/gp/product/B001EQ4JEC\">Hamburger Helper Lasagna</a> and <a href=\"http://www.amazon.com/gp/product/B001EQ4IQ6\">Hamburger Helper Beef Pasta</a> are too bland for their tastes. This flavor has just the right amount of spice and seasonings to appeal to the under-10-year-old crowd. The box suggests adding a 4.5 oz. can of Old El Paso chopped green chiles five minutes before the end of the simmer time.<br /><br />A prepared serving (one cup) has 270 calories, 570 mg of sodium and 0.5 g of fat; it also provides a good carb load - 22 grams - and 3 g of protein.<br /><br />Adding the cost of the ground hamburger and vegetables as a side dish, we are able to feed two boys for less than $5 and still have enough leftovers to prepare them a weekend lunch.<br /><br />In summary, while this isn't Haute cuisine, <a href=\"http://www.amazon.com/gp/product/B00434KRHU\">Betty Crocker Hamburger Helper Chili Macaroni</a> is an inexpensive option when pressed for time. For price and convenience, I give the product a five-star rating. For taste, I give it three stars. Again, though, I'm not the target audience, so I'm settling on a four-star rating. The slogan on the box sums it up well, \"One pound. One pan. One tasty meal.\"\n",
            "Formulating a short description...\n",
            "Review text:  <span class=\"tiny\"> Length:: 1:30 Mins<br /><br /></span>Delicious medium-roast blend with complex tones (5 stars)<br /><br />The name belies an intoxicating medium-roast blend that fuses flavors from Central America, Indonesia and East Africa. The Nantucket Blend is deliciously complex - a m&eacute;lange of four coffees from three continents - opening with the aroma of berries, spice and wine and soft floral undertones and finishing smoky and sweet with a touch of French Roast.<br /><br />According to the Green Mountain Coffee website, the blend's origin dates back more than 20 years ago, \"created at the request of a loyal customer who lived on Nantucket Island. The blend proved a winner, and the name stuck.\"<br /><br />I drink Nantucket Blend black, using Keurig's small mug (7.25 oz) setting. My wife, who will often add creamer to darker roasts, also enjoys this blend black.<br /><br />In summary, this medium-roast blend is a new favorite in our house. We first purchased Nantucket Blend during an Amazon sale for about 55 cents per Keurig cup. Regular price is about 66 cents, 15 cents higher per cup than other brands. Is it worth the additional price? Yes, but keep an eye out for sales.<br /><br />Added bonuses:<br />Nantucket Blend is certified kosher by the Orthodox Union.<br />Green Mountain Coffee is Fair Trade Certified.<br />Green Mountain Coffee is organic.<br /><br />Rating: Five stars.<br /><br />BTW: Here's my recent K-cup coffee reviews for Amazon:<br /><br />5 stars: <a href=\"http://www.amazon.com/gp/product/B004743O08\">Green Mountain Coffee Nantucket Blend</a><br />5 stars: <a href=\"http://www.amazon.com/gp/product/B001CHFUDC\">Coffee People Donut Shop Medium Roast</a><br />5 stars: <a href=\"http://www.amazon.com/gp/product/B0039556K2\">Van Houtte Chocolate Raspberry Truffle</a><br />4 stars: <a href=\"http://www.amazon.com/gp/product/B001EYUE6G\">Green Mountain Coffee Lake & Lodge Blend</a><br />4 stars: <a href=\"http://www.amazon.com/gp/product/B003C4YIFE\">Green Mountain Coffee Vermont Country Blend</a><br />4 stars: Green Mountain Coffee Wild Mountain Blueberry<br />4 stars: <a href=\"http://www.amazon.com/gp/product/B001ELL68Y\">Tully's Coffee Kona Blend</a><br />4 stars: <a href=\"http://www.amazon.com/gp/product/B004779XNW\">Green Mountain Coffee Dark Magic</a><br />3 stars: <a href=\"http://www.amazon.com/gp/product/B003JA5KKS\">Green Mountain Coffee Breakfast Blend</a><br />3 stars: <a href=\"http://www.amazon.com/gp/product/B00390VIQI\">Green Mountain Coffee Fair Trade Gingerbread</a>\n",
            "Formulating a short description...\n",
            "Review text:  <span class=\"tiny\"> Length:: 2:09 Mins<br /><br /></span>My eight-year-old son volunteered to try Nong Shim's new flavor, spicy chicken. I made a video interview of him eating the noodles for dinner, after he came home from judo practice (hungry).<br /><br />Our family enjoys Nong Shim instant noodles. We stock our pantry every autumn with bowls of ramen, yakisoba and udon. Nong Shim is the leading brand of ramyoen (ramen instant noodles) in South Korea.<br /><br />The package design is getting better. The endorsement by Professional Chefs (a 2011 Chef's Best Award) is easier to read and three colored boxes in the lower right corner note that the noodles have no MSG added, there's 30% less sodium than their regular product and that the noodles have 0 grams of trans fat.<br /><br />I recommend adding refrigerator scraps to your instant noodles; perhaps, whole kernel corn (for sweetness) or some tofu, finely chopped green onions (scallions), chopped, cooked beef, chicken or seafood. An egg is another delicious addition.<br /><br />Rating: Five stars.<br /><br />Earlier this year, J. Kenji Lopez-Alt, executive editor at Serious Eats, posted \"Ramen Hacks: 30+ Easy Ways to Upgrade Your Instant Noodles.\" I highly recommend you search out and read the full article because you will never go back to relying on the flavoring packet alone to make instant noodles.<br /><br />I distilled his tips down to these four bullet points:<br /><br />* Simple Add-ins -- Miso paste, chili bean sauce, Thai curry paste, Japanese curry powder, fish sauce, harrisa, vinegar and ponzu.<br /><br />* Vegetation -- Baby spinach, romaine lettuce, bean sprouts, thinly sliced cabbage, watercress, and scallions \"should wilt in a matter of seconds.\"<br /><br />* Eggs -- Hard boiled, soft boiled, the egg-drop method, poached eggs and fried eggs.<br /><br />* Simple Simmered Meat -- Thinly sliced meats cook in a matter of seconds directly in the pot. Chicken breast, pork tenderloin, or flank steak are all great candidates.<br /><br />Instant noodles available at Amazon that our family eats and recommends:<br /><br /><a href=\"http://www.amazon.com/gp/product/B003MOX6RA\">Nong Shim Big Bowl Noodle Udon</a><br /><a href=\"http://www.amazon.com/gp/product/B003MP136A\">Nong Shim Big Bowl Noodle Kimchi</a><br /><a href=\"http://www.amazon.com/gp/product/B00171FB7I\">Nong Shim Beef and Ginger Bowl</a><br /><a href=\"http://www.amazon.com/gp/product/B000LQNK5A\">Nong Shim Kimchi Noodle Bowl</a><br /><a href=\"http://www.amazon.com/gp/product/B0028PDFQG\">Myojo Ippeichan Yakisoba Noodles</a><br /><br />In many cases you can sign up for Amazon's Subscribe & Save program for additional savings and convenience.\n",
            "Formulating a short description...\n",
            "Review text:  Be prepared for visitors. The decadent aroma of Chocolate Raspberry Truffle imbues your kitchen (or office) as you brew this light roast from Van Houtte. We brewed a couple cups at the office (in a cubicle) and the rich aroma carried through the office air vents, attracting droopy-eyed co-workers in search of chocolate.<br /><br />Delicate for a flavored coffee, this blend made a delicious afternoon treat. And, amazingly, the artificial flavoring doesn't leave a strong chemical aftertaste. The smell of rich chocolate and raspberries lingers after the last sip, giving the impression that a team of chocolatiers just departed. Honestly, <a href=\"http://www.amazon.com/gp/product/B0039556K2\">Van Houtte Chocolate Raspberry Truffle</a> is heady stuff.<br /><br />We tested and enjoyed Van Houtte Chocolate Raspberry Truffle both on Keurig's small cup (5.25 oz) and small mug (7.25 oz) settings. According to the Van Houtte website, \"The 8-oz size makes the ideal cup of coffee, but you can vary the cup size if you want to change the coffee's strength (for example, choose a larger cup size to get a less intense cup of coffee).\"<br /><br />If you are concerned about freshness, our box of 24K cups came with an expiration date of July 10, 2011, or more than six months from our purchase date.<br /><br />Rating: Five stars.\n",
            "Formulating a short description...\n",
            "Review text:  I'm addicted to salty and tangy flavors, so when I opened my first bag of Sea Salt & Vinegar Kettle Brand chips I knew I had a perfect complement to my vegetable trays of cucumber, carrot, celery and cherry tomatoes. Skip the dip; balance the tangy chips by alternating bites of raw vegetable.<br /><br />As an Oregonian, I'm proud to share these delectable snacks with friends, especially those living outside our state and who haven't experienced gourmet chips. I tell them Kettle Brand does for potato chips what microbrews did for beer.<br /><br />Kettle Brand potato chips are unmistakable--a light gold color, rich flavor and amazing crunch. Kettle Brand chips are also a healthier snacking option than the major chip brands. Kettle Brand chips don't have trans fats, MSG or artificial flavors and colorings. The company also has a line of organic potato chips and all of their products are certified Kosher.<br /><br />I also recommend <a href=\"http://www.amazon.com/gp/product/B000G6MBV4\">Kettle Chips Honey Dijon</a> and <a href=\"http://www.amazon.com/gp/product/B000G6Q4GM\">Kettle Chips Spicy Thai</a>.<br /><br />Annette Solomon, a reporter for the Salem Statesman Journal recently noted that a glass of wine goes nicely with these chips. Solomon wrote, \"...you could be missing out on a wonderful pairing. These chips are spicy, so you would want to select a semi-sweet white wine. Also, a moderate amount of acid will subdue the strong flavors of ginger, lime, garlic and cilantro without over-powering them. Classically, a German-style Riesling fits these parameters perfectly.\"\n",
            "Formulating a short description...\n",
            "Review text:  <span class=\"tiny\"> Length:: 1:09 Mins<br /><br /></span>These cookies have an earthen texture and consistency that conjures up images of the mud pies and beach sand cakes my sons used to make. The ingredients note no less than three preservatives (TBHQ, BHT and citric acid) and nearly as many adjectives as nouns - Modified, Enriched, Bleached, Reduced and Artificial.<br /><br />Ugh.<br /><br />Instead of referencing my thesaurus for more words to express the crumbly-blandness of these cookies, I decided to make a short video. I'm sure it better illustrates the appetite-suppressing texture. As for the underwhelming taste, I turned to another resource: my sons (ages 9 and 8) are excellent food critics, albeit not the most discerning ones. I need only leave a plate of food within arm's reach while they play board games, their Xbox 360 or watch a movie. Snacks like watermelon, popcorn or licorice, disappear quickly.<br /><br />However, both boys passed on the Quaker Soft Baked Oatmeal Cookie opened for the video review. That sums it up for me.<br /><br />Rating: One star.<br /><br />Do you need to satisfy a sweet tooth? I recommend <a href=\"http://www.amazon.com/gp/product/B005BPVB9S\">Eat. Think. Smile. Crispy Thins, Sweet Cinnamon</a> instead.\n",
            "Formulating a short description...\n",
            "Review text:  Country Collection Spuds 'N Chives Potato Soup fed our family of four for about $7. The directions called for 8 cups of either water or milk; my wife added 4 cups of each. We enjoyed the soup with buttered bread.<br /><br />One package of soup: $3.17 (we saved a couple dollars on a promotional deal)<br />4 cups of milk: $1.80<br />8 slices of bread: $1.40<br />Butter: $0.55<br />Total: $6.92<br /><br /><a href=\"http://www.amazon.com/gp/product/B001EO7EU0\">Country Collection Spuds 'N Chives Potato Soup</a> is tasty. We added a couple drops of <a href=\"http://www.amazon.com/gp/product/B0051C0KJS\">Lea and Perrins Worcestershire Sauce</a> to each bowl. As I mentioned earlier, one package fed us all, including our two sons (ages 9 and 8). If you have two teenage boys, you probably should make a second package to fill them up.<br /><br />The soup's ingredients are: dehydrated potatoes, chopped onions, parsley, partially hydrogenated soybean oil, wheat flour, hydrolyzed soy protein, lactose, maltodextrin, sodium caseinate, chicken fat, salt, dipotassium phosphate, turmeric & silicon dioxide (added to prevent caking).<br /><br />These are the preparation instructions on the package: \"Empty contents into medium saucepan. Add 8 cups of water or for a richer soup add milk. Bring to a boil. Cover and simmer for 20 minutes. To thicken, remove lid and let stand for 5-10 minutes. (A crock pot works great.) You may want the soup to simmer for a couple of minutes so the little potatoes can soften.\"<br /><br />The package also lists these variations: \"For a great chowder, you can add jack cheese or mozzarella and the add oysters, clams, or throw in some corn. Garnish with bacon bits and for color, add some chopped pimento.\"<br /><br />In summary, this is a suitable (and affordable) meal for a fall or winter day. The potato soup is good by itself but I encourage you to try the variations recommended by the company.<br /><br />Rating: Five stars.\n",
            "Formulating a short description...\n",
            "Review text:  My wife likes to start her day with a taste of chocolate, so when Amazon's Subscribe & Save program began offering Chocolate Cheerios at a competitive price we placed an order. The first shipment arrived with an added surprise - each box has a Spongebob Squarepants toy inside! Our sons (ages 8 and 7) happily prepare their mother's morning bowl of cereal, knowing each serving gets them one step closer to completing the 8-piece collection.<br /><br />Of course, my wife would eat Chocolate Cheerios with or without the toy. She eats the cereal with 2% milk and a cup of black coffee because, really, you don't need cream or sugar when you're eating a bowl of chocolate cereal.<br /><br />Getting to the basics: the cereal was tightly packaged with no damage; the expiration date extends at least 12 months out, so there's no mad dash to consume six boxes at once; and the price is competitive with the supermarkets we regularly patronize. The added convenience of the cereal arriving at our doorstep rather than hauling it home in shopping bags is a bonus.<br /><br />Personally, I don't touch the stuff. I'm more of a <a href=\"http://www.amazon.com/gp/product/B002LV6LQS\">Post Raisin Bran Cereal</a> kind of guy. And, yes, of course, we buy that through Amazon's Subscribe & Save program as well.<br /><br />Rating: Five stars\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/queryfile_temp/plots/PlotNReviewEdges_2025-03-02T09:45:32.635764+00:00.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh8FdF3UpDjv"
      },
      "source": [
        "## Set tool attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trBY3hCm-9nj"
      },
      "outputs": [],
      "source": [
        "text_to_aql_to_text.name = \"Text_to_AQL_to_Text\"\n",
        "text_to_nx_algorithm_to_text.name = \"Text_to_NetworkX_cuGraph\"\n",
        "PlotReviewEdge.name = \"Plot_Review_Edge\"\n",
        "PlotNReviewEdges.name = \"Plot_N_Review_Edges\"\n",
        "\n",
        "text_to_aql_to_text.description = \"This tool is available to invoke the ArangoGraphQAChain object, which enables you to translate a Natural Language Query into AQL, execute the query, and translate the result back into Natural Language.\"\n",
        "text_to_nx_algorithm_to_text.description = \"This tool is available to invoke a NetworkX Algorithm on the ArangoDB Graph. You are responsible for accepting the Natural Language Query, establishing which algorithm needs to be executed, executing the algorithm, and translating the results back to Natural Language, with respect to the original query. If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use this tool. When you generate the Python code, only output the executable python code. Do not add the word 'python' or anything that might cause the code to return a syntax error.\"\n",
        "PlotReviewEdge.description = \"This tool is available for drawing a NetworkX graph plot of a single edge using nx.draw and matplotlib. You are responsible for accepting two (2) parameters: the start_node, and the end_node. You will use this tool to visualize the given start and end nodes, alongside their edge with their attributes, execute the plot generation code, and finally to return the path to the generated plot image file.\"\n",
        "PlotNReviewEdges.description = \"This tool is available for drawing a NetworkX graph plot of a multiple edges using nx.draw and matplotlib. You are responsible for accepting two (2) parameters: the start_node, and the end_nodes_list. You will use this tool to visualize the given start and end nodes, alongside their edges with their attributes, execute the plot generation code, and finally to return the path to the generated plot image file.\"\n",
        "\n",
        "favorite_pet.return_direct = True\n",
        "text_to_nx_algorithm_to_text.return_direct = True\n",
        "text_to_aql_to_text.return_direct = True\n",
        "\n",
        "tools = [text_to_aql_to_text, text_to_nx_algorithm_to_text, PlotReviewEdge, PlotNReviewEdges]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EDUYinu9yT9"
      },
      "source": [
        "## LangChain's rate limiter\n",
        "\n",
        "Prevent excessive calls to Mistral API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEl1a-ci93cz"
      },
      "outputs": [],
      "source": [
        "llm_rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.12,\n",
        "    check_every_n_seconds=0.09,\n",
        "    max_bucket_size=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXQbXS9YBp2t"
      },
      "source": [
        "Instantiate the llm class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta50AvP2BtJh"
      },
      "outputs": [],
      "source": [
        "llm = ChatMistralAI(\n",
        "    model = \"mistral-small-latest\",\n",
        "    temperature = 0.5,\n",
        "    max_tokens = 1000,\n",
        "    rate_limiter=llm_rate_limiter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the agent\n",
        "This will be changed soon to a langgraph implementation"
      ],
      "metadata": {
        "id": "ipny5alKE4jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, MessagesState, StateGraph\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n"
      ],
      "metadata": {
        "id": "IgwzecVVBPVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9r5CDCzDg0A",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant\"),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ") # TODO: prompt template needs to specify generated plot output\n",
        "\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    llm_with_tools = llm.bind_tools([retrieve, text_to_aql_to_text, text_to_nx_algorithm_to_text])\n",
        "    time.sleep(0.1)\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve, text_to_aql_to_text, text_to_nx_algorithm_to_text])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    system_message_content = (\n",
        "        \"You are an assistant for question-answering tasks. \"\n",
        "        \"Use the following pieces of retrieved context to answer \"\n",
        "        \"the question. If you don't know the answer, try to use other tools. Use three sentences maximum and keep the \"\n",
        "        \"answer concise.\"\n",
        "        \"\\n\\n\"\n",
        "        f\"{docs_content}\"\n",
        "    )\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "    # Run\n",
        "    time.sleep(0.1)\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Build graph\n",
        "graph_builder = StateGraph(MessagesState)\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "K5TQXpvvBJm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnNsyFPTpVrU"
      },
      "source": [
        "# User frontend\n",
        "Gradio app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn0Tv4WNdUFe"
      },
      "outputs": [],
      "source": [
        "# A queryfile is a zip that contains a .csv record of the query history,\n",
        "# and a folder of plot image files\n",
        "\n",
        "# Create temporary folder to store a queryfile temp folder: The folder is temp because it will get zipped later: One queryfile one zip, at a time\n",
        "!mkdir /content/queryfile_temp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### App logic"
      ],
      "metadata": {
        "id": "NtOH2QGlXD8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tGecMzFtRko"
      },
      "outputs": [],
      "source": [
        "from pickle import NONE\n",
        "# App logic\n",
        "\n",
        "QUERYFILE_FOLDER_PATH = \"/content/queryfile_temp\"\n",
        "\n",
        "process_log_list = [] # List of strings of verbose agent output (for debugging purposes, not recorded in queryfile)\n",
        "\n",
        "generated_plots_list = [] # List of paths to each plot in ../queryfile_temp/plots/\n",
        "query_history = pd.DataFrame(columns=[\"HumanMessage\", \"AIMessage\", \"GeneratedPlotPath\"])\n",
        "\n",
        "# Checks if temp file  exists, appends chat log (HumanMessage, AIMessage, GeneratedPlotPath) into a dataframe\n",
        "def queryfile_recorder(query_history, query : str, final_state_output : str, generated_plot_path : str):\n",
        "    global QUERYFILE_FOLDER_PATH\n",
        "    # try:\n",
        "    #   os.makedirs(QUERYFILE_FOLDER_PATH, exist_ok=False)\n",
        "    # except FileExistsError as e:\n",
        "    #   print(f\"ERROR: {e}. Temp folder already exists.\")\n",
        "    #   record_success = False\n",
        "    # else:\n",
        "    #   record_success = True\n",
        "    # Remove check for now, overwriting the queryfile is not a huge issue for testing rn\n",
        "\n",
        "# We're appending empty paths to generated plots for now, until we come up with a tool that generates matplotlib plots...\n",
        "# ... that the agent can use\n",
        "    query_history.loc[len(query_history)] = [HumanMessage(content=query), AIMessage(content=final_state_output), generated_plot_path]\n",
        "\n",
        "    return None\n",
        "\n",
        "# Saves query_history as csv. Only call after queryfile_recorder() is called.\n",
        "def save_queryfile(query_history):\n",
        "    global QUERYFILE_FOLDER_PATH\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "    query_history.to_csv(QUERYFILE_FOLDER_PATH + f\"/queryfile_{creation_datetime}.csv\")\n",
        "\n",
        "def add_process_log(new_log):\n",
        "    process_log_list.append(new_log+\"\\n\")\n",
        "\n",
        "def show_process_logs():\n",
        "    process_logs_string = \"\\n\".join(process_log_list)\n",
        "    return process_logs_string\n",
        "\n",
        "def chatbot(query: str, history):\n",
        "# Generate the output\n",
        "    if (len(query_history) == 0): # No history yet\n",
        "      final_state = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}], stream_mode})\n",
        "    else:\n",
        "      final_state = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}], \"chat_history\": query_history,})\n",
        "\n",
        "    dummy = final_state[\"output\"]\n",
        "    final_state[\"text\"] = dummy # Because Gradio's ChatInterface implementation is dumb\n",
        "\n",
        "    return final_state[\"output\"]\n",
        "\n",
        "# Wrapper function to pass to gr.ChatInterface. To handle exceptions in the outer loop, especially 429's from Mistral API\n",
        "def chatbot_wrapper(query: str, history):\n",
        "    global QUERYFILE_FOLDER_PATH\n",
        "    for attempt in range(1, 6):\n",
        "        try:\n",
        "            query_result = chatbot(query, history)\n",
        "        except Exception as e:\n",
        "            return f\"ERROR: {e}\"\n",
        "        else:\n",
        "            return query_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logging"
      ],
      "metadata": {
        "id": "iBjeuxEJXGyJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEPTyrFckOHY"
      },
      "outputs": [],
      "source": [
        "class Logger: # Implement a file object that replaces sys.stdout\n",
        "    def __init__(self, filename):\n",
        "        self.terminal = sys.stdout # the program stdout (terminal) is an instance attribute of Logger\n",
        "        self.log = open(filename, \"w\")\n",
        "\n",
        "    def write(self, message):\n",
        "        self.terminal.write(message) # redefine the write method so the program pipes stdout messages as usual\n",
        "        self.log.write(message)\n",
        "\n",
        "    def flush(self):\n",
        "        self.terminal.flush()\n",
        "        self.log.flush()\n",
        "\n",
        "    def isatty(self): # Logger won't accept any inputs, not a TTY\n",
        "        return False\n",
        "\n",
        "# Assign Logger class instance to standard output stream file object\n",
        "sys.stdout = Logger(\"output.log\") # Essentially the program stdout stream is now an instance of Logger\n",
        "\n",
        "def logs_reader(): # Reader function to pipe into gradio UI\n",
        "    sys.stdout.flush() # Force program output to be immediately written to stdout stream, and for file buffer contents be immediately written to file\n",
        "    with open(\"output.log\", \"r\") as f:\n",
        "        return f.read() # Read output log and return\n",
        "\n",
        "def plots_reader(): # Reader function to pipe generated plots from {QUERYFILE_FOLDER_PATH}/plots/\n",
        "    global QUERYFILE_FOLDER_PATH\n",
        "    image_paths = []\n",
        "    for filename in os.listdir(QUERYFILE_FOLDER_PATH+'/plots/'):\n",
        "        if filename.lower().endswith('.png'):\n",
        "            image_paths.append(os.path.join(QUERYFILE_FOLDER_PATH+'/plots/', filename))\n",
        "    return image_paths\n",
        "\n",
        "example_messages = [{\"text\": \"Can you form an AQL query that checks for a few nodes that has Finefoods_node/596 as the start node?\"},\n",
        "                    {\"text\": \"Can you create a plot of a single edge with node 596 as the start edge and node 7390 as the end node?\"},\n",
        "                    {\"text:\" \"What user (start node) has the most reviews (edges) in the graph?\"}\n",
        "                    ]\n",
        "\n",
        "chatbot_instance = gr.Chatbot(\n",
        "                    type=\"messages\",\n",
        "                    show_copy_button=True,\n",
        "                    layout=\"panel\", # LLM-style layout\n",
        "                    show_copy_all_button=True,\n",
        "                    editable=\"user\", # Allows editing of user messages\n",
        "                    avatar_images=(None, \"https://openclipart.org/image/800px/220132\"), # Show avatar only for agent\n",
        "                    examples=example_messages,\n",
        "                    )\n",
        "\n",
        "with gr.Blocks(theme=\"CultriX/gradio-theme\", fill_width=True) as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3): # Column for charts/graph and such\n",
        "            plots_gallery = gr.Gallery(\n",
        "                        value=plots_reader,\n",
        "                        label=\"Generated plots\",\n",
        "                        show_label=True,\n",
        "                        elem_id=\"gallery\",\n",
        "                        columns = [1],\n",
        "                        object_fit=\"contain\",\n",
        "                        height=\"auto\",\n",
        "                        interactive=False,\n",
        "                        every=0.5,\n",
        "                        )\n",
        "            plots_gallery.change(scroll_to_output=True)\n",
        "\n",
        "            with gr.Accordion(\"Raw process logs\"):\n",
        "                logs = gr.Textbox(show_label = False, max_lines=9) # Might be replaced by a more cool looking component\n",
        "                logs.change(scroll_to_output=True)\n",
        "\n",
        "\n",
        "        with gr.Column(scale=5): # Column for the chatbot\n",
        "            gr.ChatInterface(\n",
        "                    type=\"messages\",\n",
        "                    fill_width=True,\n",
        "                    theme=\"CultriX/gradio-theme\",\n",
        "                    chatbot=chatbot_instance,\n",
        "                    fn=chatbot_wrapper,\n",
        "                    title=\"AskYourGraph\",\n",
        "                    additional_outputs=None)\n",
        "    # Disable process log for now\n",
        "    #    demo.load(fn=logs_reader, outputs=logs, stream_every=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch Gradio app"
      ],
      "metadata": {
        "id": "hfMz-eQMFRWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/queryfile_temp/plots"
      ],
      "metadata": {
        "id": "yy02t3AaGVMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_verbose\n",
        "\n",
        "set_verbose(True) # This should really be a toggle button in the UI"
      ],
      "metadata": {
        "id": "ywVyB3qPUeQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch() # Set debug=False during deploy, program output will be in raw process logs anyway"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "Culn0RO9TBo-",
        "outputId": "236365ce-89c8-41f2-93b9-35522ada80f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ef1d100bd784755b5c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ECofRneGsbh"
      },
      "outputs": [],
      "source": [
        "# Some tested enduser prompts:\n",
        "\"Which node has the highest betweenness centrality score? Use a k value of 10? Can you also retrieve the profileName of the node?\"\n",
        "\"Can you form an AQL query that checks for a few nodes that has Finefoods_node/596 as the start node?\"\n",
        "\"Can you create a plot of a single edge with node 596 as the start edge and node 7390 as the end node? hint: Use the PlotReviewEdge tool\"\n",
        "\"Can you create a plot of a single edge with node 596 as the start edge and node 38869 as the end node? hint: Use the PlotReviewEdge tool\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process log"
      ],
      "metadata": {
        "id": "_GmpeZ3YdVQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import sys\n",
        "\n",
        "class Logger: # Implement a file object\n",
        "    def __init__(self, filename):\n",
        "        self.terminal = sys.stdout # the program stdout (terminal) is an instance attribute of Logger\n",
        "        self.log = open(filename, \"w\")\n",
        "\n",
        "    def write(self, message):\n",
        "        self.terminal.write(message) # redefine the write method so the program pipes stdout messages as usual\n",
        "        self.log.write(message)\n",
        "\n",
        "    def flush(self):\n",
        "        self.terminal.flush()\n",
        "        self.log.flush()\n",
        "\n",
        "    def isatty(self): # Logger won't accept any inputs, not a TTY\n",
        "        return False\n",
        "\n",
        "# Assign Logger class instance to standard output stream file object\n",
        "sys.stdout = Logger(\"output.log\") # Essentially the program stdout stream is now an instance of Logger\n",
        "\n",
        "def read_record_logs():\n",
        "    sys.stdout.flush() # Force program output to be immediately written to stdout stream, and for file buffer contents be immediately written to file\n",
        "    with open(\"output.log\", \"r\") as f:\n",
        "        return f.read() # Read output log and return\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    logs = gr.Textbox()\n",
        "    demo.load(read_logs, None, logs, every=1)\n"
      ],
      "metadata": {
        "id": "3ySbGNacdYpI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FqpihkfPUhoD",
        "Wk7NIJVHUb1b",
        "vHgFCPbPUV2o",
        "F8RnmqAtVNoa",
        "Buq5OV8VAIMe",
        "FvoarAr0RsrA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9618d567370f4759a85e715528c0e797": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0b6ccce5123b41099c085937f94e79df",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "(NX → ADB): Nodes \u001b[38;2;151;196;35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m (330317/330317) \u001b[33m0:00:07\u001b[0m\n     ADB Import: 'Finefoods_node' (316) \u001b[38;2;91;192;222m▰▰▰▰▰▱▱\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(NX → ADB): Nodes <span style=\"color: #97c423; text-decoration-color: #97c423\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> (330317/330317) <span style=\"color: #808000; text-decoration-color: #808000\">0:00:07</span>\n     ADB Import: 'Finefoods_node' (316) <span style=\"color: #5bc0de; text-decoration-color: #5bc0de\">▰▰▰▰▰▱▱</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "0b6ccce5123b41099c085937f94e79df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c73f45f15340d3acc8a12cbdc6bc9e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4d32bc8ccf1c498da44020dd880e3dc9",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "(NX → ADB): Edges \u001b[38;2;94;49;8m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;94;49;8m╸\u001b[0m \u001b[35m100%\u001b[0m (560001/560804) \u001b[33m0:01:09\u001b[0m\n     ADB Import: 'Finefoods_node_to_Finefoods_node' (10000) \u001b[38;2;91;192;222m▰▰▱▱▱▱▱\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(NX → ADB): Edges <span style=\"color: #5e3108; text-decoration-color: #5e3108\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> (560001/560804) <span style=\"color: #808000; text-decoration-color: #808000\">0:01:09</span>\n     ADB Import: 'Finefoods_node_to_Finefoods_node' (10000) <span style=\"color: #5bc0de; text-decoration-color: #5bc0de\">▰▰▱▱▱▱▱</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "4d32bc8ccf1c498da44020dd880e3dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}