{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andergisomon/arangodb-hackathon/blob/dev_Ander/Fork_of_1_HackathonNotebookTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set path to query file directory"
      ],
      "metadata": {
        "id": "sFRXio5-Q4Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUERYFILE_FOLDER_PATH = \"/content/queryfile_temp\""
      ],
      "metadata": {
        "id": "jUL0nDCyQ3SV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "F9a0zxInVhfT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrF3x-kONUl_"
      },
      "source": [
        "Install ```jedi``` first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0ZhvjqA3NLFN",
        "outputId": "fa358999-895b-4e63-8729-62df43a97c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi) (0.8.4)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Collecting pip-tools==6.13.0\n",
            "  Downloading pip_tools-6.13.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting build (from pip-tools==6.13.0)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (8.1.8)\n",
            "Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (24.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (0.45.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build->pip-tools==6.13.0) (24.2)\n",
            "Collecting pyproject_hooks (from build->pip-tools==6.13.0)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pyproject_hooks, build, pip-tools\n",
            "Successfully installed build-1.2.2.post1 pip-tools-6.13.0 pyproject_hooks-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install jedi\n",
        "!pip install pip-tools==6.13.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eqdvab3GMMlW",
        "outputId": "7302a699-86b2-499f-eeb1-d77c00c32bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m# This file is autogenerated by pip-compile with Python 3.11\u001b[0m\u001b[0m\n",
            "\u001b[32m# by the following command:\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m#    pip-compile /content/requirements.in\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "adbnx-adapter==5.0.6\n",
            "    \u001b[32m# via nx-arangodb\u001b[0m\u001b[0m\n",
            "certifi==2025.1.31\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "charset-normalizer==3.4.1\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "idna==3.10\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "importlib-metadata==8.6.1\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "markdown-it-py==3.0.0\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "mdurl==0.1.2\n",
            "    \u001b[32m# via markdown-it-py\u001b[0m\u001b[0m\n",
            "networkx==3.4\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   nx-arangodb\u001b[0m\u001b[0m\n",
            "numpy==1.26.4\n",
            "    \u001b[32m# via phenolrs\u001b[0m\u001b[0m\n",
            "nx-arangodb==1.3.0\n",
            "    \u001b[32m# via -r /content/requirements.in\u001b[0m\u001b[0m\n",
            "packaging==24.2\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "phenolrs==0.5.9\n",
            "    \u001b[32m# via nx-arangodb\u001b[0m\u001b[0m\n",
            "pygments==2.19.1\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "pyjwt==2.10.1\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "python-arango==8.1.6\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   nx-arangodb\n",
            "    #   phenolrs\u001b[0m\u001b[0m\n",
            "requests==2.32.3\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   python-arango\n",
            "    #   requests-toolbelt\u001b[0m\u001b[0m\n",
            "requests-toolbelt==1.0.0\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "rich==13.9.4\n",
            "    \u001b[32m# via adbnx-adapter\u001b[0m\u001b[0m\n",
            "urllib3==2.3.0\n",
            "    \u001b[32m# via\n",
            "    #   python-arango\n",
            "    #   requests\u001b[0m\u001b[0m\n",
            "zipp==3.21.0\n",
            "    \u001b[32m# via importlib-metadata\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[32m# The following packages are considered to be unsafe in a requirements file:\u001b[0m\u001b[0m\n",
            "\u001b[32m# setuptools\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!echo \"nx-arangodb\" > requirements.in\n",
        "!pip-compile '/content/requirements.in'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0bGp0SrNYYi"
      },
      "source": [
        "Install ```nx-arangodb``` based on the generated ```requirements.txt```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j4XHePCvMfcF",
        "outputId": "cdcf5760-db22-4b9f-dd1e-7dcd5177ed61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nx-arangodb\n",
            "  Downloading nx_arangodb-1.3.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting adbnx-adapter==5.0.6 (from -r requirements.txt (line 7))\n",
            "  Downloading adbnx_adapter-5.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: certifi==2025.1.31 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: importlib-metadata==8.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (8.6.1)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.0.0)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.1.2)\n",
            "Collecting networkx==3.4 (from -r requirements.txt (line 21))\n",
            "  Downloading networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (1.26.4)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (24.2)\n",
            "Collecting phenolrs==0.5.9 (from -r requirements.txt (line 31))\n",
            "  Downloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting pygments==2.19.1 (from -r requirements.txt (line 33))\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyjwt==2.10.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (2.10.1)\n",
            "Collecting python-arango==8.1.6 (from -r requirements.txt (line 37))\n",
            "  Downloading python_arango-8.1.6-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt==1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (1.0.0)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 49)) (13.9.4)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (2.3.0)\n",
            "Requirement already satisfied: zipp==3.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 55)) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter==5.0.6->-r requirements.txt (line 7)) (75.1.0)\n",
            "Using cached nx_arangodb-1.3.0-py3-none-any.whl (67 kB)\n",
            "Using cached adbnx_adapter-5.0.6-py3-none-any.whl (21 kB)\n",
            "Using cached networkx-3.4-py3-none-any.whl (1.7 MB)\n",
            "Using cached phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached python_arango-8.1.6-py3-none-any.whl (114 kB)\n",
            "Installing collected packages: pygments, networkx, python-arango, phenolrs, adbnx-adapter, nx-arangodb\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adbnx-adapter-5.0.6 networkx-3.4 nx-arangodb-1.3.0 phenolrs-0.5.9 pygments-2.19.1 python-arango-8.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install nx-arangodb -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J48LT4U7icx"
      },
      "source": [
        "Install again if some dependencies are still not resolved:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pV0dx8Ny1q64",
        "outputId": "114633a3-7eb8-4f4b-91d9-1e3b3cadf9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nx-arangodb in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: networkx<=3.4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (3.4)\n",
            "Requirement already satisfied: phenolrs~=0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (0.5.9)\n",
            "Requirement already satisfied: python-arango~=8.1 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (8.1.6)\n",
            "Requirement already satisfied: adbnx-adapter~=5.0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (5.0.6)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Install nx-arangodb via pip\n",
        "# Github: https://github.com/arangodb/nx-arangodb\n",
        "\n",
        "!pip install nx-arangodb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fL49rhZKXRXr",
        "outputId": "b505785e-c11f-4db4-a622-55428b923964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar  2 03:28:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "# 2. Check if you have an NVIDIA GPU\n",
        "# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n",
        "\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SITrT75LXRXr",
        "outputId": "66fb8758-fda0-42ba-c86a-4d2b55e0f4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: nx-cugraph-cu12 in /usr/local/lib/python3.11/dist-packages (24.12.0)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (13.3.0)\n",
            "Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (3.4)\n",
            "Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (1.26.4)\n",
            "Requirement already satisfied: pylibcugraph-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (10.3.6.82)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.1.3)\n",
            "Requirement already satisfied: pylibraft-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: rmm-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.1)\n",
            "Requirement already satisfied: cuda-python<13.0a0,<=12.6.0,>=12.0 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.6.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.61.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.82)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.44.0)\n"
          ]
        }
      ],
      "source": [
        "# 3. Install nx-cugraph via pip\n",
        "# Note: Only enable this installation if the step above is working!\n",
        "\n",
        "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yg4VdzwmXRXr",
        "outputId": "b89fdd47-49cb-4542-9a1d-b28796dab715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.5-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.41 (from langchain)\n",
            "  Downloading langchain_core-0.3.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.18-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.55-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.3.5-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.43-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.18-py3-none-any.whl (39 kB)\n",
            "Downloading langgraph_prebuilt-0.1.2-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.55-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.40\n",
            "    Uninstalling langchain-core-0.3.40:\n",
            "      Successfully uninstalled langchain-core-0.3.40\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.19\n",
            "    Uninstalling langchain-0.3.19:\n",
            "      Successfully uninstalled langchain-0.3.19\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.43 langgraph-0.3.5 langgraph-checkpoint-2.0.18 langgraph-prebuilt-0.1.2 langgraph-sdk-0.1.55 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.43)\n",
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.2.7-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
            "Downloading langchain_mistralai-0.2.7-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: langchain-mistralai\n",
            "Successfully installed langchain-mistralai-0.2.7\n"
          ]
        }
      ],
      "source": [
        "# 4. Install LangChain & LangGraph\n",
        "\n",
        "# !pip install --upgrade langchain langchain-community langchain-openai langgraph\n",
        "!pip install --upgrade langchain langchain-community langgraph\n",
        "!pip install -U langchain-core langchain-mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Locale issue might affect some Colab users\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "md0OBMeDYzvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "4b5e76a5-b563-420a-873c-21db83783c71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.1 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "XsvDwYI4Vjp8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AzIg-a9qXRXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2ab1f8-4f36-4472-851c-7a27a2fb0d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[09:54:01 +0000] [INFO]: NetworkX-cuGraph is available.\n",
            "INFO:nx_arangodb:NetworkX-cuGraph is available.\n"
          ]
        }
      ],
      "source": [
        "# 5. Import the required modules\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "\n",
        "from arango import ArangoClient\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "#from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Extra imports\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.tools.structured import StructuredTool\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "\n",
        "from arango import ArangoClient, exceptions # For AQL execution error handling\n",
        "\n",
        "import zipfile\n",
        "from datetime import datetime, timezone # For query_history csv filenaming\n",
        "from typing import Dict, List # To specify edge_attr input in tools are edge attribute dictionaries\n",
        "import itertools as it # Used in tools for plotting graphs\n",
        "import time # To delay calls to LLM, prevent 429s from messing up the inference\n",
        "import sys # To pipe stdout into a log\n",
        "import gradio as gr\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database and dataset setup"
      ],
      "metadata": {
        "id": "QCWJwfdBVmn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSmKzDgiXRXr",
        "outputId": "da82bbd2-97a4-4418-92d3-c5b68a12d77e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<StandardDatabase _system>\n"
          ]
        }
      ],
      "source": [
        "# 6. Connect to the ArangoDB database\n",
        "\n",
        "db = ArangoClient(hosts=\"https://fc54bbcbe286.arangodb.cloud:8529\").db(username=\"root\", password=\"OS0pStxrZG0wk7hVhzUW\", verify=True)\n",
        "\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J-tuJYczXRXs"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "!wget https://snap.stanford.edu/data/finefoods.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL5O-wek5N8S"
      },
      "outputs": [],
      "source": [
        "!gunzip finefoods.txt.gz # Unzip the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwikjIgc_3es"
      },
      "outputs": [],
      "source": [
        "def parse_data(file_path): # Function for parsing the dataset\n",
        "       data = []\n",
        "       current_record = {}\n",
        "       with open(file_path, 'r') as file:\n",
        "           for line in file:\n",
        "               line = line.strip()\n",
        "               #print(f\"Current line: {line}\") # Don't run print here. It will mess up Colab\n",
        "               if not line:  # Empty line indicates end of a record\n",
        "                   if current_record:\n",
        "                       data.append(current_record)\n",
        "                       current_record = {}\n",
        "               else:\n",
        "                   # Check if the delimiter is present before splitting\n",
        "                   if ': ' in line:\n",
        "                       key, value = line.split(': ', 1)\n",
        "                       current_record[key] = value\n",
        "                   else:\n",
        "                       # Handle lines without the delimiter (e.g., print or skip)\n",
        "                       print(f\"Skipping delimiterless entry in record: {line}\")\n",
        "\n",
        "                       # or continue to skip the line silently\n",
        "\n",
        "           if current_record:  # Append the last record\n",
        "               data.append(current_record)\n",
        "               print(f\"Record successfully appended: {current_record}\")\n",
        "       return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR5mRxEk2F6L"
      },
      "source": [
        "Clean the dataset. Remove bad bytes and entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMrblsAz8kel"
      },
      "outputs": [],
      "source": [
        "!iconv -f utf-8 -t utf-8 -c finefoods.txt > finefoods_cleaned.txt #sanitize finefoods.txt, some bytes are illegal in UTF-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVkd0h3z67mm",
        "outputId": "1fd39b68-fe5e-46cc-d859-d0431faa8871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping delimiterless entry in record: 88 years old. ...\n",
            "Skipping delimiterless entry in record: ...creative powers b...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: I am a voracious reader/li...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: ...creative powers b...\n"
          ]
        }
      ],
      "source": [
        "data = parse_data('finefoods_cleaned.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7ws9OYdA8nF"
      },
      "outputs": [],
      "source": [
        "finefoods = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "wH8ZEUu-3FQC",
        "outputId": "cb9fed03-8f2b-4a6d-b18a-677a6d900695"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"finefoods\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"product/productId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"B000634CK0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/userId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A1GF9C98BKZ6C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/profileName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Leeah A. Turner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/helpfulness\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0/0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"3.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1345766400\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"not sure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"i recently got a shih tzu pup and his breeder was feeding him purina pup chow but from what i read the main ingre. should be meat in a pups food so i ordered this and mixed part of her food in with this for a week or so until just feeding him this,he eats it but from hte ingredients it has fillers and biproducts in it so once the 8lb bag gets low i will be ordering some blue buffalo for him to see if he eats it because from what i hear its much better no bi-products or fillers so i will be reviewing that once we transition.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-845357b4-7a9d-4ff8-9709-bfd76a022067\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product/productId</th>\n",
              "      <th>review/userId</th>\n",
              "      <th>review/profileName</th>\n",
              "      <th>review/helpfulness</th>\n",
              "      <th>review/score</th>\n",
              "      <th>review/time</th>\n",
              "      <th>review/summary</th>\n",
              "      <th>review/text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>126349</th>\n",
              "      <td>B000634CK0</td>\n",
              "      <td>A1GF9C98BKZ6C2</td>\n",
              "      <td>Leeah A. Turner</td>\n",
              "      <td>0/0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1345766400</td>\n",
              "      <td>not sure</td>\n",
              "      <td>i recently got a shih tzu pup and his breeder ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-845357b4-7a9d-4ff8-9709-bfd76a022067')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-845357b4-7a9d-4ff8-9709-bfd76a022067 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-845357b4-7a9d-4ff8-9709-bfd76a022067');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       product/productId   review/userId review/profileName  \\\n",
              "126349        B000634CK0  A1GF9C98BKZ6C2    Leeah A. Turner   \n",
              "\n",
              "       review/helpfulness review/score review/time review/summary  \\\n",
              "126349                0/0          3.0  1345766400       not sure   \n",
              "\n",
              "                                              review/text  \n",
              "126349  i recently got a shih tzu pup and his breeder ...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finefoods.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz3fspP1aFSY",
        "outputId": "989a9ec0-7392-414a-9414-785bedf29e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       product/productId   review/userId          review/profileName  \\\n",
            "131100        B0032FKK4Q  A217RHBTO9A4LL  Barbara A. Dagger \"muzzer\"   \n",
            "\n",
            "       review/helpfulness review/score review/time review/summary  \\\n",
            "131100                0/0          5.0  1325203200         mmmmmm   \n",
            "\n",
            "                                              review/text  \n",
            "131100  Not a big fan of milk chocolate but this is gr...  \n"
          ]
        }
      ],
      "source": [
        "an_entry = finefoods[finefoods['review/profileName'].str.contains('Barbara A. Dagger')]\n",
        "\n",
        "print(an_entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU2SmLB9bT5W",
        "outputId": "504f9716-0d4b-430d-f00c-a039d687035d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not a big fan of milk chocolate but this is great!  I will buy again.  I have zero (0) will power.\n"
          ]
        }
      ],
      "source": [
        "print(finefoods[finefoods['review/userId'] == 'A217RHBTO9A4LL']['review/text'][131100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plPeun__3UP8"
      },
      "source": [
        "### Convert finefoods dataframe to NetworkX graph:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq1BDs8U73QV"
      },
      "source": [
        "Define edges using productId and userId as nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnGqBwYO49Kq",
        "outputId": "09ba4cd8-1203-44b7-b0a0-4da2cfe3697d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 330317 nodes and 560804 edges\n"
          ]
        }
      ],
      "source": [
        "# 1. Load the dataset a NetworkX Graph\n",
        "# Reference: https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html\n",
        "\n",
        "G = nx.from_pandas_edgelist(finefoods, \"product/productId\", \"review/userId\", edge_attr=[\"product/productId\", \"review/profileName\", \"review/helpfulness\", \"review/score\", \"review/summary\", \"review/text\"])\n",
        "# theres probably a more elegant way to load the column names as iterable to feed into edge_attr, but this works\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDwAaBcsXRXt"
      },
      "source": [
        "### Persist the Graph in ArangoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rARNN2aA6QUa"
      },
      "outputs": [],
      "source": [
        "G_adb = nxadb.Graph(\n",
        "    name=\"Finefoods\",\n",
        "    db=db,\n",
        "    incoming_graph_data=G,\n",
        "    write_batch_size=10000,\n",
        "    overwrite_graph=True\n",
        ")\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbb4tr628Jzt"
      },
      "source": [
        "Skip here if the Graph is already persisted in ArangoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O3ThlpALI5G9",
        "outputId": "b9602a35-9402-4244-a91c-9f4d8c33f83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[09:54:13 +0000] [INFO]: Graph 'Finefoods' exists.\n",
            "INFO:nx_arangodb:Graph 'Finefoods' exists.\n",
            "[09:54:13 +0000] [INFO]: Default node type set to 'Finefoods_node'\n",
            "INFO:nx_arangodb:Default node type set to 'Finefoods_node'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph named 'Finefoods' with 330317 nodes and 560804 edges\n"
          ]
        }
      ],
      "source": [
        "# 2. Re-connect to the same Graph\n",
        "\n",
        "G_adb = nxadb.Graph(name=\"Finefoods\", db=db)\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HWTUKp-_B8K",
        "outputId": "3fbb68ec-668e-48b0-b353-c8f3a64f0abf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_key': '126349', '_id': 'Finefoods_node/126349'}\n"
          ]
        }
      ],
      "source": [
        "print(G_adb.nodes[126349])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgv_6VlpANrH",
        "outputId": "52562d18-1448-4877-8102-91e25dd1b164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(G_adb.has_edge(318552, 318541))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqBp1MzXFVe0",
        "outputId": "1e0a560c-2238-4658-b669-e1eca7224a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_from': 'Finefoods_node/318541', '_id': 'Finefoods_node_to_Finefoods_node/552181', '_key': '552181', '_to': 'Finefoods_node/318552', 'product/productId': 'B001E5E2EK', 'review/helpfulness': '0/0', 'review/profileName': 'ragheed13', 'review/score': '5.0', 'review/summary': 'good quality', 'review/text': \"I ordered this Molasses more than once from Amazon, it's so good and I like it.\"}\n"
          ]
        }
      ],
      "source": [
        "print(G_adb.get_edge_data(318552, 318541))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpFutUC4_rHY"
      },
      "outputs": [],
      "source": [
        "print(type(G_adb.edges['0']['0']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ArangoGraph LangChain wrapper"
      ],
      "metadata": {
        "id": "uuPHgvt2WEtM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dHpIFqeYXRX0"
      },
      "outputs": [],
      "source": [
        "# 1. Create the ArangoGraph LangChain wrapper\n",
        "# Reference: https://api.python.langchain.com/en/latest/graphs/langchain_community.graphs.arangodb_graph.ArangoGraph.html\n",
        "\n",
        "arango_graph = ArangoGraph(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authenticate with Mistral API"
      ],
      "metadata": {
        "id": "f8XdiVFUWQvf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4stM5TzT-LSX"
      },
      "source": [
        "We're gonna use models from MistralAI:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCZvx_xfHX5"
      },
      "source": [
        "API Key (Do not delete this): ```A7K3bqlcBkmvNTXHOcA4tgZwfKczavLa```\n",
        "\n",
        "Alt API key: ```1fPG0PvWUZVq3jlTWPkFJvB756ux9f6k```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow9-as89rOfs",
        "outputId": "d4777287-6b04-45c3-c5b1-848c5389877f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Mistral API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "\n",
        "if \"MISTRAL_API_KEY\" not in os.environ:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent tools"
      ],
      "metadata": {
        "id": "1sJAHeFNVKpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for converting natural language to AQL and back to natural language"
      ],
      "metadata": {
        "id": "FqpihkfPUhoD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "HsJQ3t_HXRX1"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"This tool is available to invoke the\n",
        "    ArangoGraphQAChain object, which enables you to\n",
        "    translate a Natural Language Query into AQL, execute\n",
        "    the query, and translate the result back into Natural Language.\n",
        "    \"\"\"\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "    \tllm=llm,\n",
        "    \tgraph=arango_graph,\n",
        "    \tverbose=True,\n",
        "      allow_dangerous_requests=True,\n",
        "      max_aql_generation_attempts = 4\n",
        "    )\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 5\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            result = chain.invoke(query)\n",
        "        except exceptions.ArangoServerError as e:\n",
        "            attempt = attempt + 1\n",
        "            print(\"Attempt number\", attempt)\n",
        "            print(f\"AQL EXEC ERROR: {e}\")\n",
        "            return f\"AQL EXEC ERROR: {e}\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return str(result[\"result\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for converting natural language to nx algo and back to natural language"
      ],
      "metadata": {
        "id": "Wk7NIJVHUb1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "05kgQHvWXRX1"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language (AQL), then do not use\n",
        "    this tool.\n",
        "    When you generate the Python code, only output the executable python code. Do not add the word \"python\" or anything\n",
        "    that might cause the code to return a syntax error.\n",
        "    \"\"\"\n",
        "    ########################\n",
        "\n",
        "    llm_invoke_prompt = f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & concise answer. Avoid setting this variable to a long sequence.\n",
        "    Your code:\n",
        "    \"\"\"\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(llm_invoke_prompt).content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print('-'*10)\n",
        "    print(text_to_nx_cleaned)\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 5\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            text_to_nx_final = llm.invoke(llm_invoke_prompt).content\n",
        "            text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx_final, flags=re.MULTILINE).strip()\n",
        "            print(\"Attempt number\", attempt)\n",
        "            exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        except BaseException as e:\n",
        "            attempt = attempt + 1\n",
        "            print(\"Attempt number\", attempt)\n",
        "            print(f\"EXEC ERROR: {e}\")\n",
        "            return f\"EXEC ERROR: {e}\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print('-'*10)\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"3) Formulating final answer\")\n",
        "\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed the following python code to help me answer my query:\n",
        "\n",
        "        ---\n",
        "        {text_to_nx_final}\n",
        "        ---\n",
        "\n",
        "        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n",
        "\n",
        "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
        "        answer my query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for plotting a single review"
      ],
      "metadata": {
        "id": "vHgFCPbPUV2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "bwslo8iux23Q"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def PlotReviewEdge(start_node : int, end_node : int): # Hard-coded tool for generating plot of a single review edge by some user\n",
        "    \"\"\"This tool is available for drawing a NetworkX graph plot of a single edge using nx.draw and matplotlib.\n",
        "    You are responsible for accepting two (2) parameters: the start_node, and the end_node.\n",
        "    You will use this tool to visualize the given start and end nodes, alongside their edge with their attributes,\n",
        "    execute the plot generation code, and finally to return the path to the generated plot image file.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    # Create an empty graph to draw\n",
        "    G = nx.Graph()\n",
        "    product_asin_dict = {}\n",
        "\n",
        "    edge_attr = G_adb.get_edge_data(start_node, end_node, default = False) # Will return False if edge not found, and will return the edge data dict if found\n",
        "\n",
        "    if type(edge_attr) == bool:\n",
        "        raise RuntimeError(f\"edge_attr = {edge_attr}: Edge does not exist\")\n",
        "\n",
        "    product_asin_dict[f\"{int(end_node)}\"] = edge_attr['product/productId']\n",
        "\n",
        "    G.add_edge(start_node, end_node, **edge_attr)\n",
        "    # Generate short summary of the review/text attribute, review/summary attribute is mostly useless\n",
        "    review_text_summary = ShortDescriptionGenerator(review_text = edge_attr.get('review/text'))\n",
        "\n",
        "    G_pos = nx.spring_layout(G)\n",
        "\n",
        "    # Get the edge data for the single edge\n",
        "    edge_data = G.get_edge_data(start_node, end_node)\n",
        "\n",
        "    # Draw the graph with the single edge\n",
        "    nx.draw(G, pos=G_pos, with_labels=True, node_color=\"skyblue\", node_size=200, edge_color=\"skyblue\")\n",
        "\n",
        "    # Generate short summary of the review/text attribute\n",
        "    review_text_summary = ShortDescriptionGenerator(review_text = edge_data.get('review/text'))\n",
        "\n",
        "    # Add linebreaks to review text summary label\n",
        "    words = review_text_summary.split()\n",
        "    result = []\n",
        "    for i in range(0, len(words), 7): # 7 words per line\n",
        "        result.append(\" \".join(words[i : i + 7]))\n",
        "\n",
        "    review_text_summary = \"\\n\".join(result)\n",
        "\n",
        "    # Add edge labels (attributes)\n",
        "    nx.draw_networkx_edge_labels(\n",
        "        G,\n",
        "        pos=G_pos,\n",
        "        font_size=11,\n",
        "        edge_labels={(start_node, end_node): f\"{review_text_summary}\\nUser: {edge_data.get('review/profileName')}\"},\n",
        "        rotate=False)\n",
        "\n",
        "    # Node labels\n",
        "    product_node_labels = {\n",
        "        int(end_node): f\"\\nproductId (ASIN)=\\n{product_asin}\"\n",
        "        for end_node, product_asin in product_asin_dict.items()\n",
        "    }\n",
        "\n",
        "    label_pos = {} # Add offset for product node label\n",
        "    for node, (x, y) in G_pos.items():\n",
        "        label_pos[node] = (x + 0.1, y - 0.1)\n",
        "\n",
        "    nx.draw_networkx_labels(\n",
        "        G,\n",
        "        pos=label_pos,\n",
        "        labels=product_node_labels, #{**user_node_labels, **product_node_labels},\n",
        "        font_size=10,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "    )\n",
        "\n",
        "    # Save the plot\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    try:\n",
        "        plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotReviewEdge_{creation_datetime}.png\"\n",
        "    except FileNotFoundError:\n",
        "        os.makedirs(QUERYFILE_FOLDER_PATH + f\"/plots/\", exist_ok=True)\n",
        "        plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotReviewEdge_{creation_datetime}.png\"\n",
        "\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return plot_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool for plotting multiple reviews from one user"
      ],
      "metadata": {
        "id": "FON_Kp0yU85w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "bUJ_PbVNcMLI"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def PlotNReviewEdges(start_node : int, end_nodes_list : List[int]): # Hard-coded tool for generating plot of N review edges made by the same user\n",
        "    \"\"\"This tool is available for drawing a NetworkX graph plot of a multiple edges using nx.draw and matplotlib.\n",
        "    You are responsible for accepting two (2) parameters: the start_node, and the end_nodes_list.\n",
        "    You will use this tool to visualize the given start and end nodes, alongside their edges with their attributes,\n",
        "    execute the plot generation code, and finally to return the path to the generated plot image file.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    # Create an empty graph to draw\n",
        "    G = nx.Graph()\n",
        "    connectionstyle = [f\"arc3,rad={r}\" for r in it.accumulate([0.15] * 8)] # Assuming a user wrote at most 8 reviews\n",
        "    # connectionstyle = [f\"angle3,angleA=90,angleB={r}\" for r in it.accumulate([30] * 8)]\n",
        "\n",
        "    edge_review_text_summary_dict = {}\n",
        "    product_asin_dict = {}\n",
        "\n",
        "    for start_node, end_node in it.product([start_node], end_nodes_list): # Put start_node in a list to make it iterable\n",
        "        edge_attr = G_adb.get_edge_data(start_node, end_node, default = False) # Will return False if edge not found, and will return the edge data dict if found\n",
        "        if type(edge_attr) == bool:\n",
        "            continue # Skip to the next iteration\n",
        "        else:\n",
        "            G.add_edge(start_node, end_node, **edge_attr)\n",
        "\n",
        "            time.sleep(1.5) # Prevent LLM calls that are too fast\n",
        "            # Generate short summary of the review/text attribute, review/summary attribute is mostly useless\n",
        "            review_text_summary = ShortDescriptionGenerator(review_text = edge_attr.get('review/text'))\n",
        "\n",
        "            # Add linebreaks to review text summary label\n",
        "            words = review_text_summary.split()\n",
        "            result = []\n",
        "            words_per_line = 3 # 3 words per line\n",
        "            for i in range(0, len(words), words_per_line):\n",
        "                result.append(\" \".join(words[i : i + words_per_line]))\n",
        "            review_text_summary = \"\\n\".join(result)\n",
        "\n",
        "            edge_review_text_summary_dict[f\"({int(start_node)}, {int(end_node)})\"] = review_text_summary\n",
        "            product_asin_dict[f\"{int(end_node)}\"] = edge_attr['product/productId']\n",
        "\n",
        "    G_pos = nx.spring_layout(G)\n",
        "    # Draw the graph. pos unspecified defaulting to spring_layout\n",
        "    nx.draw(G, pos=G_pos, with_labels=True, node_color=\"skyblue\", node_size=200, edge_color=\"skyblue\")\n",
        "\n",
        "    edges_attrs_label = {\n",
        "        (start_node, end_node): f\"ASIN={edge_attrs['product/productId']}\\nsummary=\\n{edge_review_text_summary_dict.get(f'({int(start_node)}, {int(end_node)})')}\"\n",
        "        for start_node, end_node, edge_attrs in G.edges(data=True) # data=True return a 3-tuple (u, v, ddict).\n",
        "    }\n",
        "\n",
        "    # Add edge labels (attributes)\n",
        "    nx.draw_networkx_edge_labels(\n",
        "        G,\n",
        "        pos=G_pos,\n",
        "        font_size=8,\n",
        "        edge_labels = edges_attrs_label,\n",
        "        connectionstyle='arc3,rad=0.3',\n",
        "        label_pos=0.6,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "        rotate=False,\n",
        "    )\n",
        "\n",
        "    # Node labels\n",
        "    product_node_labels = {\n",
        "        int(end_node): f\"\\nproductId (ASIN)=\\n{product_asin}\"\n",
        "        for end_node, product_asin in product_asin_dict.items()\n",
        "    }\n",
        "\n",
        "    label_pos = {} # Add offset for product node label\n",
        "    for node, (x, y) in G_pos.items():\n",
        "        label_pos[node] = (x + 0.1, y - 0.1)\n",
        "\n",
        "    nx.draw_networkx_labels(\n",
        "        G,\n",
        "        pos=label_pos,\n",
        "        labels=product_node_labels, #{**user_node_labels, **product_node_labels},\n",
        "        font_size=10,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "    )\n",
        "\n",
        "    # Save the plot\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    try:\n",
        "        plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotNReviewEdges_{creation_datetime}.png\"\n",
        "    except FileNotFoundError:\n",
        "        os.makedirs(QUERYFILE_FOLDER_PATH + f\"/plots/\", exist_ok=True)\n",
        "        plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotNReviewEdges_{creation_datetime}.png\"\n",
        "\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return plot_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function that returns a short description of review"
      ],
      "metadata": {
        "id": "NPjuv48XW7pI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "3dq4tFxV-bB4"
      },
      "outputs": [],
      "source": [
        "# Since LLM behavior is pretty deterministic when it comes to this task, this won't be a tool but just a simple\n",
        "# function that another tool can call\n",
        "def ShortDescriptionGenerator(review_text : str): # Condense the review/text into a short sentence that can fit in the plot\n",
        "  \"\"\"\n",
        "  This tool is for generating a short but concise description of the review text (review/text).\n",
        "  The description must be one sentence long, with no more than 10 words.\n",
        "\n",
        "  Only use this tool when a review/text is provided.\n",
        "  \"\"\"\n",
        "\n",
        "#   print(\"Formulating a short description...\\nReview text: \", review_text)\n",
        "\n",
        "  short_desc = llm.invoke(f\"\"\"\n",
        "  A review text is provided to me. The review text is as follows: {review_text}\n",
        "\n",
        "  Based on the provided review text, generate a short but concise description of the review text.\n",
        "  The description must be one sentence long with no more than 10 words.\n",
        "\n",
        "  Your 10-word-long description:\n",
        "\n",
        "  \"\"\").content\n",
        "\n",
        "  return short_desc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tools for common operations"
      ],
      "metadata": {
        "id": "mz4kXBySddvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certain operations are routine and can benefit from a dedicated tool."
      ],
      "metadata": {
        "id": "kj70W4YxdkLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GetEdgeBetweenTwoNodes"
      ],
      "metadata": {
        "id": "gL2E3WaHdovB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brLeuRCadx4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get_profileName"
      ],
      "metadata": {
        "id": "jClSPDsMdypk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIjubbVrd2UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GetASIN"
      ],
      "metadata": {
        "id": "8z03oEVCd2lR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rdOJfe95i4PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GetReviewText"
      ],
      "metadata": {
        "id": "WUHT6usMi4in"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q6rY3hThi8aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Search_profileName"
      ],
      "metadata": {
        "id": "vnrw8iTni8rz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpVQ74YZjAYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh8FdF3UpDjv"
      },
      "source": [
        "## Set tool attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "trBY3hCm-9nj"
      },
      "outputs": [],
      "source": [
        "text_to_aql_to_text.name = \"Text_to_AQL_to_Text\"\n",
        "text_to_nx_algorithm_to_text.name = \"Text_to_NetworkX_cuGraph\"\n",
        "PlotReviewEdge.name = \"Plot_Review_Edge\"\n",
        "PlotNReviewEdges.name = \"Plot_N_Review_Edges\"\n",
        "\n",
        "text_to_aql_to_text.description = \"This tool is available to invoke the ArangoGraphQAChain object, which enables you to translate a Natural Language Query into AQL, execute the query, and translate the result back into Natural Language. If the user asks for the edge between two nodes or multiple edges between a set of nodes, you must list out the edge attribute for each edges.\"\n",
        "text_to_nx_algorithm_to_text.description = \"This tool is available to invoke a NetworkX Algorithm on the ArangoDB Graph. You are responsible for accepting the Natural Language Query, establishing which algorithm needs to be executed, executing the algorithm, and translating the results back to Natural Language, with respect to the original query. If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use this tool. When you generate the Python code, only output the executable python code. Do not add the word 'python' or anything that might cause the code to return a syntax error.\"\n",
        "PlotReviewEdge.description = \"This tool is available for drawing a NetworkX graph plot of a single edge using nx.draw and matplotlib. You are responsible for accepting two (2) parameters: the start_node, and the end_node. You will use this tool to visualize the given start and end nodes, alongside their edge with their attributes, execute the plot generation code, and finally to return the path to the generated plot image file.\"\n",
        "PlotNReviewEdges.description = \"This tool is available for drawing a NetworkX graph plot of a multiple edges using nx.draw and matplotlib. You are responsible for accepting two (2) parameters: the start_node, and the end_nodes_list. You will use this tool to visualize the given start and end nodes, alongside their edges with their attributes, execute the plot generation code, and finally to return the path to the generated plot image file.\"\n",
        "\n",
        "text_to_nx_algorithm_to_text.return_direct = True\n",
        "text_to_aql_to_text.return_direct = True\n",
        "\n",
        "tools = [text_to_aql_to_text, text_to_nx_algorithm_to_text, PlotReviewEdge, PlotNReviewEdges]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EDUYinu9yT9"
      },
      "source": [
        "## LangChain's rate limiter\n",
        "\n",
        "Prevent excessive calls to Mistral API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "UEl1a-ci93cz"
      },
      "outputs": [],
      "source": [
        "llm_rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.13,\n",
        "    check_every_n_seconds=0.08,\n",
        "    max_bucket_size=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXQbXS9YBp2t"
      },
      "source": [
        "Instantiate the llm class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Ta50AvP2BtJh"
      },
      "outputs": [],
      "source": [
        "llm = ChatMistralAI(\n",
        "    model = \"mistral-small-latest\",\n",
        "    temperature = 0.5,\n",
        "    max_tokens = 1000,\n",
        "    rate_limiter=llm_rate_limiter\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the agent"
      ],
      "metadata": {
        "id": "ipny5alKE4jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangGraph Implementation\n",
        "from typing import Literal\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, MessagesState, StateGraph\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import convert_to_messages # To simulate verbose outputs\n",
        "from langgraph.types import Command\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "from langchain_core.messages.human import HumanMessage\n",
        "from ast import literal_eval # poor LangGraph code leads to requiring this package"
      ],
      "metadata": {
        "id": "0QM5OTWzkhKY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_prompt = \"You are an agent equipped with various tools to answer queries related to a network database of product reviews.\"\n",
        "\n",
        "AskYourGraph_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt=init_prompt,\n",
        ")\n",
        "\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"AskYourGraph\", AskYourGraph_agent)\n",
        "builder.add_edge(START, \"AskYourGraph\")\n",
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "XWEjkqlQOtDM"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio frontend"
      ],
      "metadata": {
        "id": "MkAv2ITa9U89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parser(prompt, messages):\n",
        "    messages.append(gr.ChatMessage(role=\"user\", content=prompt))\n",
        "    yield messages\n",
        "\n",
        "    for chunk in graph.stream(\n",
        "        {\"messages\": [(\"user\", f\"{prompt}\")]}, subgraphs=False\n",
        "    ):\n",
        "        for node_name, node_update in chunk.items():\n",
        "            for m in node_update[\"messages\"]:\n",
        "\n",
        "                if (type(m) == AIMessage and len(m.tool_calls) != 0): # For messages from the agent with a tool call\n",
        "\n",
        "                    for m in node_update[\"messages\"]:\n",
        "                        if type(m) == AIMessage and 'tool_calls' in m.additional_kwargs:\n",
        "                            toolname = m.additional_kwargs['tool_calls'][0][\"function\"][\"name\"]\n",
        "                            toolargs = m.additional_kwargs['tool_calls'][0][\"function\"][\"arguments\"]\n",
        "\n",
        "                            args_str = \"\"\n",
        "\n",
        "                            if literal_eval(toolargs):\n",
        "                                for arg, argval in literal_eval(toolargs).items(): # Amazing design decision by LangChain to store the args as a string in a dictionary\n",
        "                                    if not argval: # Check if it's an empty string\n",
        "                                        args_str + f\"None\"\n",
        "                                    else:\n",
        "                                        args_str + f\"{arg} = {argval}\\n\"\n",
        "                            else:\n",
        "                                args_str = \"None\"\n",
        "\n",
        "                            messages.append(gr.ChatMessage(role=\"assistant\", content=f\"Arguments passed: {args_str}\",\n",
        "                                                metadata={\"title\": f\"🛠️ Calling tool {toolname}\"}))\n",
        "                            yield messages\n",
        "\n",
        "                elif (type(m) == ToolMessage):\n",
        "                    for m in node_update[\"messages\"]:\n",
        "                        if type(m) == ToolMessage:\n",
        "                            toolname = m.name\n",
        "                            toolresult = m.content\n",
        "                            tool_msg = f\"Tool '{toolname}' returned result:\\n{toolresult}\"\n",
        "\n",
        "                            messages.append(gr.ChatMessage(role=\"assistant\", content=tool_msg,\n",
        "                                metadata={\"title\": f\"🛠️ Tool {toolname} execution finished\"}))\n",
        "                            yield messages\n",
        "\n",
        "                        else:\n",
        "                            continue\n",
        "\n",
        "                elif (type(m) == AIMessage and len(m.tool_calls) == 0):\n",
        "                    messages.append(gr.ChatMessage(role=\"assistant\", content=m.content))\n",
        "                    yield messages"
      ],
      "metadata": {
        "id": "GlopM30MhceZ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plots_reader(): # Reader function to pipe generated plots from {QUERYFILE_FOLDER_PATH}/plots/\n",
        "    image_paths = []\n",
        "    try:\n",
        "        for filename in os.listdir(QUERYFILE_FOLDER_PATH+'/plots/'):\n",
        "            if filename.lower().endswith('.png'):\n",
        "                image_paths.append(os.path.join(QUERYFILE_FOLDER_PATH+'/plots/', filename))\n",
        "    except FileNotFoundError:\n",
        "        os.makedirs(QUERYFILE_FOLDER_PATH + f\"/plots/\", exist_ok=True)\n",
        "        for filename in os.listdir(QUERYFILE_FOLDER_PATH+'/plots/'):\n",
        "            if filename.lower().endswith('.png'):\n",
        "                image_paths.append(os.path.join(QUERYFILE_FOLDER_PATH+'/plots/', filename))\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "with gr.Blocks(theme=\"CultriX/gradio-theme\", fill_width=True, fill_height=True) as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3): # Column for charts/graph and such\n",
        "            plots_gallery = gr.Gallery(\n",
        "                        value=plots_reader,\n",
        "                        label=\"Generated plots\",\n",
        "                        show_label=True,\n",
        "                        elem_id=\"gallery\",\n",
        "                        columns = [1],\n",
        "                        object_fit=\"contain\",\n",
        "                        height=\"auto\",\n",
        "                        interactive=False,\n",
        "                        every=0.5,\n",
        "                        )\n",
        "            plots_gallery.change(scroll_to_output=True)\n",
        "\n",
        "        with gr.Column(scale=5): # Column for the chatbot\n",
        "            chatbot_instance = gr.Chatbot(\n",
        "                    type=\"messages\",\n",
        "                    layout=\"bubble\", # chat-style layout\n",
        "                    avatar_images=(None, \"https://openclipart.org/image/800px/220132\"), # Show avatar only for agent\n",
        "                    )\n",
        "\n",
        "            input = gr.Textbox(lines=1, submit_btn=True, show_label=False)\n",
        "            input.submit(parser, [input, chatbot_instance], [chatbot_instance])\n",
        "            input.submit(lambda x: gr.update(value=''), [],[input])"
      ],
      "metadata": {
        "id": "LFf6Bt8hfjaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff9bd90-c3ca-4df5-b1ad-7f78b548689a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/utils.py:1024: UserWarning: Expected 1 arguments for function <function <lambda> at 0x78f6703442c0>, received 0.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/utils.py:1028: UserWarning: Expected at least 1 arguments for function <function <lambda> at 0x78f6703442c0>, received 0.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AXxrFkirgjnw",
        "outputId": "abeb9d1c-2f52-4281-c949-2d5213fdff28"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://30a556f83ae116f5e4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://30a556f83ae116f5e4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/helpers.py:968: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  LIMIT 1\n",
            "  RETURN edge\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'_key': '10001', '_id': 'Finefoods_node_to_Finefoods_node/10001', '_from': 'Finefoods_node/812', '_to': 'Finefoods_node/81298', '_rev': '_jUZQcDm-AD', 'product/productId': 'B006W5WDS4', 'review/profileName': 'K. Stuckey \"kateling\"', 'review/helpfulness': '0/0', 'review/score': '5.0', 'review/summary': 'SO tasty', 'review/text': 'I picked up a box of Special K red berries recently on a whim, tried it, went back and got more. I am in day 2 of the Special K challenge and hope to lose 6 pounds in 2 weeks as advertised. The serving size is generous, the flakes are crispy and flavorful and the strawberries taste just like fresh!'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/helpers.py:968: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 715, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2103, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 735, in async_iteration\n",
            "    return await anext(iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 729, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 712, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 873, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "               ^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-69-5fe6bd5c0af5>\", line 5, in parser\n",
            "    for chunk in graph.stream(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 2024, in stream\n",
            "    for _ in runner.tick(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
            "    run_with_retry(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
            "    input = step.invoke(input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 2367, in invoke\n",
            "    for chunk in self.stream(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 2024, in stream\n",
            "    for _ in runner.tick(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
            "    run_with_retry(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
            "    input = step.invoke(input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 302, in invoke\n",
            "    ret = context.run(self.func, *args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/chat_agent_executor.py\", line 642, in call_model\n",
            "    response = cast(AIMessage, model_runnable.invoke(state, config))\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 3029, in invoke\n",
            "    input = context.run(step.invoke, input, config)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 5365, in invoke\n",
            "    return self.bound.invoke(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 307, in invoke\n",
            "    self.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 843, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 683, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 908, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 547, in _generate\n",
            "    response = self.completion_with_retry(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 466, in completion_with_retry\n",
            "    rtn = _completion_with_retry(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 463, in _completion_with_retry\n",
            "    _raise_on_error(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 170, in _raise_on_error\n",
            "    raise httpx.HTTPStatusError(\n",
            "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n",
            "During task with name 'agent' and id 'e28ba939-7f9a-a0b1-6fdd-e9ebc2388cb7'\n",
            "During task with name 'AskYourGraph' and id 'bac3f10a-b3b2-630f-e080-9f008ac4f9fc'\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/helpers.py:968: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/helpers.py:968: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/helpers.py:968: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://30a556f83ae116f5e4.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ECofRneGsbh"
      },
      "outputs": [],
      "source": [
        "# Some tested enduser prompts:\n",
        "\"Using AQL, can you find a random edge between two nodes and return the edge attributes for that edge?\"\n",
        "\"Using AQL, can you find a random edge between two nodes and return the edge attributes for that edge? List out the edge attributes\"\n",
        "\"Which node has the highest betweenness centrality score? Use a k value of 10? Can you also retrieve the profileName of the node?\"\n",
        "\"Can you form an AQL query that checks for a few nodes that has Finefoods_node/596 as the start node?\"\n",
        "\"Can you create a plot of a single edge with node 596 as the start edge and node 7390 as the end node? hint: Use the PlotReviewEdge tool\"\n",
        "\"Can you create a plot of a single edge with node 596 as the start edge and node 38869 as the end node? hint: Use the PlotReviewEdge tool\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mz4kXBySddvE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}