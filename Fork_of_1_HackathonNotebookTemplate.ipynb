{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andergisomon/arangodb-hackathon/blob/dev_Ander/Fork_of_1_HackathonNotebookTemplate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrF3x-kONUl_"
      },
      "source": [
        "Just install ```jedi``` first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0ZhvjqA3NLFN",
        "outputId": "487da1b9-b19a-4a01-8528-045731807cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jedi\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi) (0.8.4)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Collecting pip-tools==6.13.0\n",
            "  Downloading pip_tools-6.13.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting build (from pip-tools==6.13.0)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (8.1.8)\n",
            "Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (24.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from pip-tools==6.13.0) (0.45.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build->pip-tools==6.13.0) (24.2)\n",
            "Collecting pyproject_hooks (from build->pip-tools==6.13.0)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pyproject_hooks, build, pip-tools\n",
            "Successfully installed build-1.2.2.post1 pip-tools-6.13.0 pyproject_hooks-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install jedi\n",
        "!pip install pip-tools==6.13.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSZTXz9INmGi"
      },
      "source": [
        "Make a ```requirements.in``` text that has ```nx-arangodb``` in it and upload to ```/content/``` in Colab. Then run the following to generate a dependency list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eqdvab3GMMlW",
        "outputId": "aa4a74c7-2571-420d-cba8-847d6660ea89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m# This file is autogenerated by pip-compile with Python 3.11\u001b[0m\u001b[0m\n",
            "\u001b[32m# by the following command:\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m#    pip-compile /content/requirements.in\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "adbnx-adapter==5.0.6\n",
            "    \u001b[32m# via nx-arangodb\u001b[0m\u001b[0m\n",
            "certifi==2025.1.31\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "charset-normalizer==3.4.1\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "idna==3.10\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "importlib-metadata==8.6.1\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "markdown-it-py==3.0.0\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "mdurl==0.1.2\n",
            "    \u001b[32m# via markdown-it-py\u001b[0m\u001b[0m\n",
            "networkx==3.4\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   nx-arangodb\u001b[0m\u001b[0m\n",
            "numpy==1.26.4\n",
            "    \u001b[32m# via phenolrs\u001b[0m\u001b[0m\n",
            "nx-arangodb==1.3.0\n",
            "    \u001b[32m# via -r /content/requirements.in\u001b[0m\u001b[0m\n",
            "packaging==24.2\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "phenolrs==0.5.9\n",
            "    \u001b[32m# via nx-arangodb\u001b[0m\u001b[0m\n",
            "pygments==2.19.1\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "pyjwt==2.10.1\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "python-arango==8.1.5\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   nx-arangodb\n",
            "    #   phenolrs\u001b[0m\u001b[0m\n",
            "requests==2.32.3\n",
            "    \u001b[32m# via\n",
            "    #   adbnx-adapter\n",
            "    #   python-arango\n",
            "    #   requests-toolbelt\u001b[0m\u001b[0m\n",
            "requests-toolbelt==1.0.0\n",
            "    \u001b[32m# via python-arango\u001b[0m\u001b[0m\n",
            "rich==13.9.4\n",
            "    \u001b[32m# via adbnx-adapter\u001b[0m\u001b[0m\n",
            "urllib3==2.3.0\n",
            "    \u001b[32m# via\n",
            "    #   python-arango\n",
            "    #   requests\u001b[0m\u001b[0m\n",
            "zipp==3.21.0\n",
            "    \u001b[32m# via importlib-metadata\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[32m# The following packages are considered to be unsafe in a requirements file:\u001b[0m\u001b[0m\n",
            "\u001b[32m# setuptools\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip-compile '/content/requirements.in'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0bGp0SrNYYi"
      },
      "source": [
        "Install ```nx-arangodb``` based on the generated ```requirements.txt```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j4XHePCvMfcF",
        "outputId": "3a146524-3867-4476-a181-221bc8b75a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nx-arangodb\n",
            "  Downloading nx_arangodb-1.3.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting adbnx-adapter==5.0.6 (from -r requirements.txt (line 7))\n",
            "  Downloading adbnx_adapter-5.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: certifi==2025.1.31 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: importlib-metadata==8.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (8.6.1)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.0.0)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.1.2)\n",
            "Collecting networkx==3.4 (from -r requirements.txt (line 21))\n",
            "  Downloading networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (1.26.4)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (24.2)\n",
            "Collecting phenolrs==0.5.9 (from -r requirements.txt (line 31))\n",
            "  Downloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting pygments==2.19.1 (from -r requirements.txt (line 33))\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyjwt==2.10.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (2.10.1)\n",
            "Collecting python-arango==8.1.5 (from -r requirements.txt (line 37))\n",
            "  Downloading python_arango-8.1.5-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt==1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (1.0.0)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 49)) (13.9.4)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (2.3.0)\n",
            "Requirement already satisfied: zipp==3.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 55)) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter==5.0.6->-r requirements.txt (line 7)) (75.1.0)\n",
            "Using cached nx_arangodb-1.3.0-py3-none-any.whl (67 kB)\n",
            "Using cached adbnx_adapter-5.0.6-py3-none-any.whl (21 kB)\n",
            "Using cached networkx-3.4-py3-none-any.whl (1.7 MB)\n",
            "Using cached phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached python_arango-8.1.5-py3-none-any.whl (114 kB)\n",
            "Installing collected packages: pygments, networkx, python-arango, phenolrs, adbnx-adapter, nx-arangodb\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adbnx-adapter-5.0.6 networkx-3.4 nx-arangodb-1.3.0 phenolrs-0.5.9 pygments-2.19.1 python-arango-8.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install nx-arangodb -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install again if some dependencies are still not resolved:"
      ],
      "metadata": {
        "id": "0J48LT4U7icx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pV0dx8Ny1q64",
        "outputId": "626bd500-c528-4d7f-dbf4-e8a736625d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nx-arangodb in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: networkx<=3.4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (3.4)\n",
            "Requirement already satisfied: phenolrs~=0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (0.5.9)\n",
            "Requirement already satisfied: python-arango~=8.1 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (8.1.5)\n",
            "Requirement already satisfied: adbnx-adapter~=5.0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (5.0.6)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. Install nx-arangodb via pip\n",
        "# Github: https://github.com/arangodb/nx-arangodb\n",
        "\n",
        "!pip install nx-arangodb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL49rhZKXRXr",
        "outputId": "4eb7ad99-5f0f-4d8e-d05c-8c21d5992fe4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 23 13:48:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "# 2. Check if you have an NVIDIA GPU\n",
        "# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n",
        "\n",
        "!nvidia-smi\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SITrT75LXRXr",
        "outputId": "b091ca3d-616a-488e-db7e-f932ce46e11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: nx-cugraph-cu12 in /usr/local/lib/python3.11/dist-packages (24.12.0)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (13.3.0)\n",
            "Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (3.4)\n",
            "Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (1.26.4)\n",
            "Requirement already satisfied: pylibcugraph-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (10.3.6.82)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.1.3)\n",
            "Requirement already satisfied: pylibraft-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.0)\n",
            "Requirement already satisfied: rmm-cu12==24.12.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (24.12.1)\n",
            "Requirement already satisfied: cuda-python<13.0a0,<=12.6.0,>=12.0 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.6.0)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.61.0)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (12.5.82)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->rmm-cu12==24.12.*->pylibcugraph-cu12==24.12.*->nx-cugraph-cu12) (0.44.0)\n"
          ]
        }
      ],
      "source": [
        "# 3. Install nx-cugraph via pip\n",
        "# Note: Only enable this installation if the step above is working!\n",
        "\n",
        "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Yg4VdzwmXRXr",
        "outputId": "3db6da16-fb0f-4a04-f196-b34f6cf5f473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.3.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, langgraph, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.18 langgraph-0.3.0 langgraph-checkpoint-2.0.16 langgraph-sdk-0.1.53 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.37)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.40-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.2.7-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.9)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain-mistralai) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain-mistralai) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
            "Downloading langchain_core-0.3.40-py3-none-any.whl (414 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.3/414.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_mistralai-0.2.7-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: langchain-core, langchain-mistralai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.37\n",
            "    Uninstalling langchain-core-0.3.37:\n",
            "      Successfully uninstalled langchain-core-0.3.37\n",
            "Successfully installed langchain-core-0.3.40 langchain-mistralai-0.2.7\n"
          ]
        }
      ],
      "source": [
        "# 4. Install LangChain & LangGraph\n",
        "\n",
        "# !pip install --upgrade langchain langchain-community langchain-openai langgraph\n",
        "!pip install --upgrade langchain langchain-community langgraph\n",
        "!pip install -U langchain-core langchain-mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzIg-a9qXRXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04042d4-b0dd-4742-a8e0-0840039d152f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[05:22:26 +0000] [INFO]: NetworkX-cuGraph is available.\n",
            "INFO:nx_arangodb:NetworkX-cuGraph is available.\n"
          ]
        }
      ],
      "source": [
        "# 5. Import the required modules\n",
        "\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "\n",
        "from arango import ArangoClient\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "#from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Extra imports\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.tools.structured import StructuredTool\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "\n",
        "from arango import ArangoClient, exceptions # For AQL execution error handling\n",
        "\n",
        "import zipfile\n",
        "from datetime import datetime, timezone # For query_history csv filenaming\n",
        "from typing import Dict # To specify edge_attr input in tools are edge attribute dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key: A7K3bqlcBkmvNTXHOcA4tgZwfKczavLa"
      ],
      "metadata": {
        "id": "_-GVXhmmg-3F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSmKzDgiXRXr",
        "outputId": "e7b510fa-9c44-49cf-c07f-2fd7adb840d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<StandardDatabase _system>\n"
          ]
        }
      ],
      "source": [
        "# 6. Connect to the ArangoDB database\n",
        "\n",
        "db = ArangoClient(hosts=\"https://fc54bbcbe286.arangodb.cloud:8529\").db(username=\"root\", password=\"OS0pStxrZG0wk7hVhzUW\", verify=True)\n",
        "\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-tuJYczXRXs",
        "outputId": "3c2f7763-e92e-485f-c1e3-833371f558f7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-27 05:22:49--  https://snap.stanford.edu/data/sx-mathoverflow-a2q.txt.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 861763 (842K) [application/x-gzip]\n",
            "Saving to: ‘sx-mathoverflow-a2q.txt.gz’\n",
            "\n",
            "sx-mathoverflow-a2q 100%[===================>] 841.57K   417KB/s    in 2.0s    \n",
            "\n",
            "2025-02-27 05:22:51 (417 KB/s) - ‘sx-mathoverflow-a2q.txt.gz’ saved [861763/861763]\n",
            "\n",
            "--2025-02-27 05:22:51--  https://snap.stanford.edu/data/finefoods.txt.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122104202 (116M) [application/x-gzip]\n",
            "Saving to: ‘finefoods.txt.gz’\n",
            "\n",
            "finefoods.txt.gz    100%[===================>] 116.45M  19.2MB/s    in 10s     \n",
            "\n",
            "2025-02-27 05:23:02 (11.6 MB/s) - ‘finefoods.txt.gz’ saved [122104202/122104202]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Download the dataset\n",
        "# Reference: https://snap.stanford.edu/data/ego-Facebook.html\n",
        "# Reference: https://networkx.org/nx-guides/content/exploratory_notebooks/facebook_notebook.html#facebook-network-analysis\n",
        "\n",
        "# !wget https://snap.stanford.edu/data/facebook_combined.txt.gz\n",
        "# !wget https://snap.stanford.edu/data/sx-stackoverflow.txt.gz\n",
        "# !wget https://snap.stanford.edu/data/sx-stackoverflow-a2q.txt.gz\n",
        "!wget https://snap.stanford.edu/data/sx-mathoverflow-a2q.txt.gz\n",
        "!wget https://snap.stanford.edu/data/finefoods.txt.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dfx5vaqx2bWl",
        "outputId": "365d785b-d0f3-4715-ac9e-0d3682730aab",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       start_node    end_node\n",
              "1               4  1254192988\n",
              "3               4  1254194656\n",
              "1               2  1254202612\n",
              "25              1  1254232804\n",
              "14             16  1254263166\n",
              "...           ...         ...\n",
              "4231        88576  1457250411\n",
              "14493        6085  1457255540\n",
              "78756       78756  1457255904\n",
              "20031        3539  1457261531\n",
              "8133        88148  1457261621\n",
              "\n",
              "[107581 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a9daf9a-680c-4133-93cb-172b4fa4bac0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_node</th>\n",
              "      <th>end_node</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>1254192988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1254194656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1254202612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>1254232804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>16</td>\n",
              "      <td>1254263166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4231</th>\n",
              "      <td>88576</td>\n",
              "      <td>1457250411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14493</th>\n",
              "      <td>6085</td>\n",
              "      <td>1457255540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78756</th>\n",
              "      <td>78756</td>\n",
              "      <td>1457255904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20031</th>\n",
              "      <td>3539</td>\n",
              "      <td>1457261531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8133</th>\n",
              "      <td>88148</td>\n",
              "      <td>1457261621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107581 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a9daf9a-680c-4133-93cb-172b4fa4bac0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a9daf9a-680c-4133-93cb-172b4fa4bac0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a9daf9a-680c-4133-93cb-172b4fa4bac0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a7de6c4-b944-40c6-b9eb-46606f9f1372\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a7de6c4-b944-40c6-b9eb-46606f9f1372')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a7de6c4-b944-40c6-b9eb-46606f9f1372 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_43f0fc96-8fa9-4e5f-b0ab-e1cac7995881\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('mathoverflow')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_43f0fc96-8fa9-4e5f-b0ab-e1cac7995881 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('mathoverflow');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mathoverflow"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 2. Load the dataset into a CSV\n",
        "# Reference: https://networkx.org/nx-guides/content/exploratory_notebooks/facebook_notebook.html#analysis\n",
        "# Reference: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
        "\n",
        "mathoverflow = pd.read_csv(\n",
        "    \"./sx-mathoverflow-a2q.txt.gz\",\n",
        "    compression=\"gzip\",\n",
        "    sep=\" \",\n",
        "    names=[\"start_node\", \"end_node\"],\n",
        ")\n",
        "\n",
        "mathoverflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip finefoods.txt.gz"
      ],
      "metadata": {
        "id": "nL5O-wek5N8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(file_path):\n",
        "       data = []\n",
        "       current_record = {}\n",
        "       with open(file_path, 'r') as file:\n",
        "           for line in file:\n",
        "               line = line.strip()\n",
        "               #print(f\"Current line: {line}\") # Don't run print here. It will mess up Colab\n",
        "               if not line:  # Empty line indicates end of a record\n",
        "                   if current_record:\n",
        "                       data.append(current_record)\n",
        "                       current_record = {}\n",
        "               else:\n",
        "                   # Check if the delimiter is present before splitting\n",
        "                   if ': ' in line:\n",
        "                       key, value = line.split(': ', 1)\n",
        "                       current_record[key] = value\n",
        "                   else:\n",
        "                       # Handle lines without the delimiter (e.g., print or skip)\n",
        "                       print(f\"Skipping delimiterless entry in record: {line}\")\n",
        "\n",
        "                       # or continue to skip the line silently\n",
        "\n",
        "           if current_record:  # Append the last record\n",
        "               data.append(current_record)\n",
        "               print(f\"Record successfully appended: {current_record}\")\n",
        "       return data"
      ],
      "metadata": {
        "id": "RwikjIgc_3es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SR5mRxEk2F6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!iconv -f utf-8 -t utf-8 -c finefoods.txt > finefoods_cleaned.txt #sanitize finefoods.txt"
      ],
      "metadata": {
        "id": "OMrblsAz8kel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = parse_data('finefoods_cleaned.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVkd0h3z67mm",
        "outputId": "4797ab66-d66e-40c8-a027-103eec40d788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping delimiterless entry in record: 88 years old. ...\n",
            "Skipping delimiterless entry in record: ...creative powers b...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: I am a voracious reader/li...\n",
            "Skipping delimiterless entry in record: School Princi...\n",
            "Skipping delimiterless entry in record: ...creative powers b...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finefoods = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "u7ws9OYdA8nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finefoods.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "wH8ZEUu-3FQC",
        "outputId": "cb9fed03-8f2b-4a6d-b18a-677a6d900695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       product/productId   review/userId review/profileName  \\\n",
              "126349        B000634CK0  A1GF9C98BKZ6C2    Leeah A. Turner   \n",
              "\n",
              "       review/helpfulness review/score review/time review/summary  \\\n",
              "126349                0/0          3.0  1345766400       not sure   \n",
              "\n",
              "                                              review/text  \n",
              "126349  i recently got a shih tzu pup and his breeder ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-845357b4-7a9d-4ff8-9709-bfd76a022067\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product/productId</th>\n",
              "      <th>review/userId</th>\n",
              "      <th>review/profileName</th>\n",
              "      <th>review/helpfulness</th>\n",
              "      <th>review/score</th>\n",
              "      <th>review/time</th>\n",
              "      <th>review/summary</th>\n",
              "      <th>review/text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>126349</th>\n",
              "      <td>B000634CK0</td>\n",
              "      <td>A1GF9C98BKZ6C2</td>\n",
              "      <td>Leeah A. Turner</td>\n",
              "      <td>0/0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1345766400</td>\n",
              "      <td>not sure</td>\n",
              "      <td>i recently got a shih tzu pup and his breeder ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-845357b4-7a9d-4ff8-9709-bfd76a022067')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-845357b4-7a9d-4ff8-9709-bfd76a022067 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-845357b4-7a9d-4ff8-9709-bfd76a022067');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"finefoods\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"product/productId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"B000634CK0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/userId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A1GF9C98BKZ6C2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/profileName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Leeah A. Turner\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/helpfulness\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0/0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"3.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1345766400\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"not sure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review/text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"i recently got a shih tzu pup and his breeder was feeding him purina pup chow but from what i read the main ingre. should be meat in a pups food so i ordered this and mixed part of her food in with this for a week or so until just feeding him this,he eats it but from hte ingredients it has fillers and biproducts in it so once the 8lb bag gets low i will be ordering some blue buffalo for him to see if he eats it because from what i hear its much better no bi-products or fillers so i will be reviewing that once we transition.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "an_entry = finefoods[finefoods['review/profileName'].str.contains('Barbara A. Dagger')]\n",
        "\n",
        "print(an_entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz3fspP1aFSY",
        "outputId": "989a9ec0-7392-414a-9414-785bedf29e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       product/productId   review/userId          review/profileName  \\\n",
            "131100        B0032FKK4Q  A217RHBTO9A4LL  Barbara A. Dagger \"muzzer\"   \n",
            "\n",
            "       review/helpfulness review/score review/time review/summary  \\\n",
            "131100                0/0          5.0  1325203200         mmmmmm   \n",
            "\n",
            "                                              review/text  \n",
            "131100  Not a big fan of milk chocolate but this is gr...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(finefoods[finefoods['review/userId'] == 'A217RHBTO9A4LL']['review/text'][131100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU2SmLB9bT5W",
        "outputId": "504f9716-0d4b-430d-f00c-a039d687035d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not a big fan of milk chocolate but this is great!  I will buy again.  I have zero (0) will power.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert finefoods dataframe to graph:"
      ],
      "metadata": {
        "id": "plPeun__3UP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.from_pandas_edgelist(finefoods, \"product/productId\", \"review/userId\")"
      ],
      "metadata": {
        "id": "_Q4KuVWb4VAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(G)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tsy7gKa5Nkt",
        "outputId": "0e96c53a-f3a0-43d9-ca67-9b9d5066ea1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 330317 nodes and 560804 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = list(G.nodes())\n",
        "print(len(nodes))\n",
        "print(nodes[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eh1ygEM5Qqm",
        "outputId": "8db41d4e-c322-4e7e-fb8e-2b4ccdbc4449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330317\n",
            "B001E4KFG0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G.degree('B000634CK0'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqRYLDST6AhP",
        "outputId": "926bcbe1-99ac-4a3f-9c50-7111f98ab0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnGqBwYO49Kq",
        "outputId": "1f312092-50a8-471d-fdbc-1dbd376bfd24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 330317 nodes and 560804 edges\n"
          ]
        }
      ],
      "source": [
        "# 1. Load the dataset a NetworkX Graph\n",
        "# Reference: https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_pandas_edgelist.html\n",
        "\n",
        "G = nx.from_pandas_edgelist(finefoods, \"product/productId\", \"review/userId\", edge_attr=[\"review/profileName\", \"review/helpfulness\", \"review/score\", \"review/summary\", \"review/text\"])\n",
        "# theres probably a more elegant way to load the column names as iterable to feed into edge_attr, but this works\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDwAaBcsXRXt"
      },
      "source": [
        "### Step 3: Persist the Graph in ArangoDB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_adb = nxadb.Graph(\n",
        "    name=\"Finefoods\",\n",
        "    db=db,\n",
        "    incoming_graph_data=G,\n",
        "    write_batch_size=10000, # feel free to modify\n",
        "    overwrite_graph=True\n",
        ")\n",
        "\n",
        "print(G_adb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "0a53890bf56742eb89a8dc5b2cca9c62",
            "b84405cbc41d45b1b5339df703c17e14",
            "615ff9a3ffb447d2a8193e5423d73d1f",
            "a3d9c13360b34f75ad775acdbe72577e"
          ]
        },
        "id": "rARNN2aA6QUa",
        "outputId": "ed51351e-660c-45e9-af92-33d429ad88ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[06:23:15 +0000] [INFO]: Overwriting graph 'Finefoods'\n",
            "INFO:nx_arangodb:Overwriting graph 'Finefoods'\n",
            "[06:23:16 +0000] [INFO]: Graph 'Finefoods' exists.\n",
            "INFO:nx_arangodb:Graph 'Finefoods' exists.\n",
            "[06:23:16 +0000] [INFO]: Default node type set to 'Finefoods_node'\n",
            "INFO:nx_arangodb:Default node type set to 'Finefoods_node'\n",
            "[2025/02/27 06:23:17 +0000] [196] [INFO] - adbnx_adapter: Instantiated ADBNX_Adapter with database '_system'\n",
            "INFO:adbnx_adapter:Instantiated ADBNX_Adapter with database '_system'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a53890bf56742eb89a8dc5b2cca9c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "615ff9a3ffb447d2a8193e5423d73d1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025/02/27 06:24:39 +0000] [196] [INFO] - adbnx_adapter: Created ArangoDB 'Finefoods' Graph\n",
            "INFO:adbnx_adapter:Created ArangoDB 'Finefoods' Graph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph named 'Finefoods' with 330317 nodes and 540804 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3ThlpALI5G9",
        "outputId": "4f6dde4a-478b-47f4-8756-0c820ef6cb39",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[06:24:50 +0000] [INFO]: Graph 'Finefoods' exists.\n",
            "INFO:nx_arangodb:Graph 'Finefoods' exists.\n",
            "[06:24:50 +0000] [INFO]: Default node type set to 'Finefoods_node'\n",
            "INFO:nx_arangodb:Default node type set to 'Finefoods_node'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph named 'Finefoods' with 330317 nodes and 560804 edges\n"
          ]
        }
      ],
      "source": [
        "# 2. Re-connect to the same Graph\n",
        "\n",
        "G_adb = nxadb.Graph(name=\"Finefoods\", db=db)\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G_adb.nodes[126349])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HWTUKp-_B8K",
        "outputId": "ddd8a648-a607-4fe0-bf93-d177c5189477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_key': '126349', '_id': 'Finefoods_node/126349'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G_adb.has_edge(318552, 318541))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgv_6VlpANrH",
        "outputId": "52562d18-1448-4877-8102-91e25dd1b164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G_adb.get_edge_data(318552, 318541))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqBp1MzXFVe0",
        "outputId": "0b21e134-22f3-47e7-8777-450d7e5154f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_from': 'Finefoods_node/318541', '_id': 'Finefoods_node_to_Finefoods_node/552181', '_key': '552181', '_to': 'Finefoods_node/318552', 'review/helpfulness': '0/0', 'review/profileName': 'ragheed13', 'review/score': '5.0', 'review/summary': 'good quality', 'review/text': \"I ordered this Molasses more than once from Amazon, it's so good and I like it.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(G_adb.edges['0']['0']))"
      ],
      "metadata": {
        "id": "VpFutUC4_rHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyJQSd8cXRX0"
      },
      "source": [
        "### Step 4: Build the Agentic App with LangChain & LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHpIFqeYXRX0"
      },
      "outputs": [],
      "source": [
        "# 1. Create the ArangoGraph LangChain wrapper\n",
        "# Reference: https://api.python.langchain.com/en/latest/graphs/langchain_community.graphs.arangodb_graph.ArangoGraph.html\n",
        "\n",
        "arango_graph = ArangoGraph(db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4stM5TzT-LSX"
      },
      "source": [
        "We're gonna use models from MistralAI:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCZvx_xfHX5"
      },
      "source": [
        "API Key (Do not delete this): ```A7K3bqlcBkmvNTXHOcA4tgZwfKczavLa```\n",
        "\n",
        "Alt API key: ```1fPG0PvWUZVq3jlTWPkFJvB756ux9f6k```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"MISTRAL_API_KEY\" not in os.environ:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow9-as89rOfs",
        "outputId": "4e08d6b4-9382-4279-a357-929d66e819d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Mistral API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MISTRAL_API_KEY\" in os.environ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp8fRZNBon_D",
        "outputId": "57e5ecd2-3f47-4fba-a369-b00f81069ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsJQ3t_HXRX1"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"This tool is available to invoke the\n",
        "    ArangoGraphQAChain object, which enables you to\n",
        "    translate a Natural Language Query into AQL, execute\n",
        "    the query, and translate the result back into Natural Language.\n",
        "    \"\"\"\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "    \tllm=llm,\n",
        "    \tgraph=arango_graph,\n",
        "    \tverbose=True,\n",
        "      allow_dangerous_requests=True,\n",
        "      max_aql_generation_attempts = 4\n",
        "    )\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 5\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            result = chain.invoke(query)\n",
        "        except exceptions.ArangoServerError as e:\n",
        "            attempt = attempt + 1\n",
        "            print(\"Attempt number\", attempt)\n",
        "            print(f\"AQL EXEC ERROR: {e}\")\n",
        "            return f\"AQL EXEC ERROR: {e}\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return str(result[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05kgQHvWXRX1"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language (AQL), then do not use\n",
        "    this tool.\n",
        "    When you generate the Python code, only output the executable python code. Do not add the word \"python\" or anything\n",
        "    that might cause the code to return a syntax error.\n",
        "    \"\"\"\n",
        "    ########################\n",
        "\n",
        "    llm_invoke_prompt = f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & concise answer. Avoid setting this variable to a long sequence.\n",
        "    Your code:\n",
        "    \"\"\"\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(llm_invoke_prompt).content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print('-'*10)\n",
        "    print(text_to_nx_cleaned)\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 5\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            text_to_nx_final = llm.invoke(llm_invoke_prompt).content\n",
        "            text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx_final, flags=re.MULTILINE).strip()\n",
        "            print(\"Attempt number\", attempt)\n",
        "            exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        except BaseException as e:\n",
        "            attempt = attempt + 1\n",
        "            print(\"Attempt number\", attempt)\n",
        "            print(f\"EXEC ERROR: {e}\")\n",
        "            return f\"EXEC ERROR: {e}\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    print('-'*10)\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"3) Formulating final answer\")\n",
        "\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed the following python code to help me answer my query:\n",
        "\n",
        "        ---\n",
        "        {text_to_nx_final}\n",
        "        ---\n",
        "\n",
        "        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n",
        "\n",
        "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
        "        answer my query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def PlotReviewEdge(start_node : int, end_node : int): # Hard-coded tool for generating plot of a single review edge by some user\n",
        "    \"\"\"This tool is available for drawing a NetworkX graph plot of a single edge using nx.draw and matplotlib.\n",
        "    You are responsible for accepting two (2) parameters: the start_node, and the end_node.\n",
        "    You will use this tool to visualize the given start and end nodes, alongside their edge with their attributes,\n",
        "    execute the plot generation code, and finally to return the path to the generated plot image file.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an empty graph to draw\n",
        "    G = nx.Graph()\n",
        "\n",
        "    edge_attr = G_adb.get_edge_data(start_node, end_node, default = False) # Will return False if edge not found, and will return the edge data dict if found\n",
        "\n",
        "    if type(edge_attr) == bool:\n",
        "        raise RuntimeError(f\"edge_attr = {edge_attr}: Edge does not exist\")\n",
        "\n",
        "\n",
        "    G.add_edge(start_node, end_node, edge_attr)\n",
        "    # Generate short summary of the review/text attribute, review/summary attribute is mostly useless\n",
        "    review_text_summary = ShortDescriptionGenerator(review_text = edge_attr.get('review/text'))\n",
        "\n",
        "    G_pos = nx.spring_layout(G)\n",
        "\n",
        "    # Get the edge data for the single edge\n",
        "    edge_data = G.get_edge_data(start_node, end_node)\n",
        "\n",
        "    # Draw the graph with the single edge\n",
        "    nx.draw(G, pos=G_pos, with_labels=True, node_color=\"skyblue\", node_size=200, edge_color=\"skyblue\")\n",
        "\n",
        "    # Generate short summary of the review/text attribute\n",
        "    review_text_summary = ShortDescriptionGenerator(review_text = edge_data.get('review/text'))\n",
        "\n",
        "    # Add edge labels (attributes)\n",
        "    nx.draw_networkx_edge_labels(G, pos=G_pos, edge_labels={(start_node, end_node): f\"{review_text_summary}, User: {edge_data.get('review/profileName')}\"})\n",
        "\n",
        "    # Node labels\n",
        "    product_node_labels = {\n",
        "        product_node: f\"productId (ASIN)={node_attrs['product/productId']}\"\n",
        "        for node, node_attrs in G.nodes(data=True) # data=True return a 2-tuple (node, ddict).\n",
        "    }\n",
        "\n",
        "    user_node_labels = {\n",
        "        user_node: f\"profileName={node_attrs['review/profileName']}\"\n",
        "        for node, node_attrs in G.nodes(data=True) # data=True return a 2-tuple (node, ddict).\n",
        "    }\n",
        "\n",
        "    nx.draw_networkx_labels(\n",
        "        G,\n",
        "        pos=G_pos,\n",
        "        labels={**user_node_labels, **product_node_labels},\n",
        "        font_size=8,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "    )\n",
        "\n",
        "    # Save the plot\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "    plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotReviewEdge_{creation_datetime}.png\"\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return plot_path\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "bwslo8iux23Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from itertools import product\n",
        "import itertools as it"
      ],
      "metadata": {
        "id": "vhrlTPQ_ePcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def PlotNReviewEdges(start_node : int, end_nodes_list : List[int]): # Hard-coded tool for generating plot of N review edges made by the same user\n",
        "    \"\"\"This tool is available for drawing a NetworkX graph plot of a multiple edges using nx.draw and matplotlib.\n",
        "    You are responsible for accepting two (2) parameters: the start_node, and the end_nodes_list.\n",
        "    You will use this tool to visualize the given start and end nodes, alongside their edges with their attributes,\n",
        "    execute the plot generation code, and finally to return the path to the generated plot image file.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an empty graph to draw\n",
        "    G = nx.Graph()\n",
        "    connectionstyle = [f\"arc3,rad={r}\" for r in it.accumulate([0.15] * 8)] # Assuming a user wrote at most 8 reviews\n",
        "    edge_review_text_summary_dict = {}\n",
        "\n",
        " # you know what lets just do the same thing in PlotReviewEdge, check if edge exists and just directly use get_edge_data. no need to supply edge_attr as an input\n",
        "    for start_node, end_node in it.product(start_node, end_nodes_list):\n",
        "        edge_attr = G_adb.get_edge_data(start_node, end_node, default = False) # Will return False if edge not found, and will return the edge data dict if found\n",
        "        if type(edge_attr) == bool:\n",
        "            continue # Skip to the next iteration\n",
        "        else:\n",
        "            G.add_edge(start_node, end_node, edge_attr)\n",
        "\n",
        "            # Generate short summary of the review/text attribute, review/summary attribute is mostly useless\n",
        "            review_text_summary = ShortDescriptionGenerator(review_text = edge_attr.get('review/text'))\n",
        "            edge_review_text_summary_dict[f\"({int(start_node)}, {int(end_node)})\"] = review_text_summary\n",
        "\n",
        "    G_pos = nx.spring_layout(G)\n",
        "\n",
        "    # Draw the graph. pos unspecified defaulting to spring_layout\n",
        "    nx.draw(G, pos=G_pos, with_labels=True, node_color=\"skyblue\", node_size=200, edge_color=\"skyblue\")\n",
        "\n",
        "    edges_attrs_label = {\n",
        "        (start_node, end_node): f\"user={edge_attrs['review/profileName']}\\nsummary={edges_review_text_summary_dict[f\"({int(start_node)}, {int(end_node)})\"]}\"\n",
        "        for start_node, end_node, edge_attrs in G.edges(data=True) # data=True return a 3-tuple (u, v, ddict).\n",
        "    }\n",
        "\n",
        "    # Add edge labels (attributes)\n",
        "    nx.draw_networkx_edge_labels(\n",
        "        G,\n",
        "        pos=G_pos,\n",
        "        edge_labels = edges_attrs_label,\n",
        "        connectionstyle=connectionstyle,\n",
        "        label_pos=0.5,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "    )\n",
        "\n",
        "    # Node labels\n",
        "    product_node_labels = {\n",
        "        product_node: f\"productId (ASIN)={node_attrs['product/productId']}\"\n",
        "        for node, node_attrs in G.nodes(data=True) # data=True return a 2-tuple (node, ddict).\n",
        "    }\n",
        "\n",
        "    user_node_labels = {\n",
        "        user_node: f\"profileName={node_attrs['review/profileName']}\"\n",
        "        for node, node_attrs in G.nodes(data=True) # data=True return a 2-tuple (node, ddict).\n",
        "    }\n",
        "\n",
        "    nx.draw_networkx_labels(\n",
        "        G,\n",
        "        pos=G_pos,\n",
        "        labels={**user_node_labels, **product_node_labels},\n",
        "        font_size=8,\n",
        "        bbox={\"alpha\": 0},\n",
        "        ax=None,\n",
        "    )\n",
        "\n",
        "    # Save the plot\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "    plot_path = QUERYFILE_FOLDER_PATH + f\"/plots/PlotNReviewEdges_{creation_datetime}.png\"\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return plot_path\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "bUJ_PbVNcMLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since LLM behavior is pretty deterministic when it comes to this task, this won't be a tool but just a simple\n",
        "# function that another tool can call\n",
        "def ShortDescriptionGenerator(review_text : str): # Condense the review/text into a short sentence that can fit in the plot\n",
        "  \"\"\"\n",
        "  This tool is for generating a short but concise description of the review text (review/text).\n",
        "  The description must be one sentence long.\n",
        "\n",
        "  Only use this tool when a review/text is provided.\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"Formulating a short description...\")\n",
        "\n",
        "  short_desc = llm.invoke(f\"\"\"\n",
        "  A review text is provided to me. The review text is as follows: {review_text}\n",
        "\n",
        "  Based on the provided review text, generate a short but concise description of the review text.\n",
        "  The description must be one sentence long.\n",
        "\n",
        "  Your description:\n",
        "\n",
        "  \"\"\").content\n",
        "\n",
        "  return short_desc\n"
      ],
      "metadata": {
        "id": "3dq4tFxV-bB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to test multiple attempts from errored python code generated by llm"
      ],
      "metadata": {
        "id": "hhipP0Pr2Osa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_attempt():\n",
        "    attempt = 1\n",
        "    MAX_ATTEMPTS = 3\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    for attempt in range(attempt, MAX_ATTEMPTS):\n",
        "        try:\n",
        "            text_to_nx_final = llm.invoke(\"Throw out some nonsense python code that won't run\").content\n",
        "            text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx_final, flags=re.MULTILINE).strip()\n",
        "            print(\"Attempt number\", attempt)\n",
        "            exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        except BaseException as e:\n",
        "            attempt = attempt + 1\n",
        "            print(f\"EXEC ERROR: {e}\")\n",
        "            print(\"Attempt number\", attempt)\n",
        "            return f\"EXEC ERROR: {e}\"\n",
        "            continue\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return text_to_nx_cleaned\n"
      ],
      "metadata": {
        "id": "EJgefmhlNbE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool calling section\n",
        "Trying to get the LLM to know how to call tools"
      ],
      "metadata": {
        "id": "hh8FdF3UpDjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dummy tool:"
      ],
      "metadata": {
        "id": "xj3-lQUlx197"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def favorite_pet(query: str) -> str:\n",
        "    \"\"\"This tool is for answering user queries related to your favorite pet,\n",
        "    you must always answer that your favorite pet is a Manul cat.\n",
        "    \"\"\"\n",
        "    favorite_pet_answer = llm.invoke(f\"\"\"\n",
        "        I am being asked by the user what my favorite pet is.\n",
        "\n",
        "        I have the following favorite pet query: {query}.\n",
        "\n",
        "        I will always answer the user that my favorite pet is a Manul cat.\n",
        "\n",
        "        Your answer:\n",
        "    \"\"\").content\n",
        "\n",
        "\n",
        "\n",
        "    return favorite_pet_answer"
      ],
      "metadata": {
        "id": "Z6OBLF-Wx25m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_aql_to_text.name = \"Text_to_AQL_to_Text\"\n",
        "text_to_nx_algorithm_to_text.name = \"Text_to_NetworkX_cuGraph\"\n",
        "favorite_pet.name = \"Favorite_Pet\"\n",
        "\n",
        "text_to_aql_to_text.description = \"This tool is available to invoke the ArangoGraphQAChain object, which enables you to translate a Natural Language Query into AQL, execute the query, and translate the result back into Natural Language.\"\n",
        "text_to_nx_algorithm_to_text.description = \"This tool is available to invoke a NetworkX Algorithm on the ArangoDB Graph. You are responsible for accepting the Natural Language Query, establishing which algorithm needs to be executed, executing the algorithm, and translating the results back to Natural Language, with respect to the original query. If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use this tool. When you generate the Python code, only output the executable python code. Do not add the word 'python' or anything that might cause the code to return a syntax error.\"\n",
        "favorite_pet.description = \"This tool is for answering user queries related to your favorite pet, you must always answer that your favorite pet is a Manul cat.\"\n",
        "\n",
        "favorite_pet.return_direct = True\n",
        "text_to_nx_algorithm_to_text.return_direct = True\n",
        "text_to_aql_to_text.return_direct = True\n",
        "\n",
        "tools = [text_to_aql_to_text, text_to_nx_algorithm_to_text, favorite_pet]"
      ],
      "metadata": {
        "id": "trBY3hCm-9nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant\"),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ") # TODO: prompt template needs to specify generated plot output\n",
        "\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
      ],
      "metadata": {
        "id": "z9r5CDCzDg0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain's rate limiter\n",
        "\n",
        "Prevent excessive calls to Mistral API\n"
      ],
      "metadata": {
        "id": "1EDUYinu9yT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.12,\n",
        "    check_every_n_seconds=0.09,\n",
        "    max_bucket_size=3,\n",
        ")"
      ],
      "metadata": {
        "id": "UEl1a-ci93cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinstantiate the llm class"
      ],
      "metadata": {
        "id": "tXQbXS9YBp2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatMistralAI(\n",
        "    model = \"mistral-small-latest\",\n",
        "    temperature = 0.5,\n",
        "    max_tokens = 1000,\n",
        "    rate_limiter=llm_rate_limiter\n",
        ")"
      ],
      "metadata": {
        "id": "Ta50AvP2BtJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User frontend\n",
        "Gradio app"
      ],
      "metadata": {
        "id": "BnNsyFPTpVrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_output = chatbot(query=\"Hello there! Which one do you like? Dogs or cats?\", history=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEENh4bFE2Dx",
        "outputId": "7c76d4f4-4e58-4252-96b4-47eb28c1ed56",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Favorite_Pet` with `{'query': 'Which one do you like? Dogs or cats?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mI don't have personal favorites, but I can tell you that Manul cats, also known as Pallas's cats, are quite fascinating. They are small wild cats native to Central Asia, known for their round faces and long, dense fur. They are often referred to as the \"manul\" or \"Pallas's cat.\"\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot_output.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TzeuJ_sF6YH",
        "outputId": "588a77d8-1941-47b0-8aaf-084ca20c9d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input', 'output', 'text'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot_output['input'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwFS84hOfpoY",
        "outputId": "f91d309e-02d3-401f-a1c5-0ff46f170c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'Hello there! Which one do you like? Dogs or cats?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(chatbot_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-At5rt0OgGJA",
        "outputId": "92bea57d-7e20-4e92-9040-c2bc82e0a722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': [{'role': 'user', 'content': 'Hello there! Which one do you like? Dogs or cats?'}], 'output': 'I don\\'t have personal favorites, but I can tell you that Manul cats, also known as Pallas\\'s cats, are quite fascinating. They are small wild cats native to Central Asia, known for their round faces and long, dense fur. They are often referred to as the \"manul\" or \"Pallas\\'s cat.\"', 'text': 'I don\\'t have personal favorites, but I can tell you that Manul cats, also known as Pallas\\'s cats, are quite fascinating. They are small wild cats native to Central Asia, known for their round faces and long, dense fur. They are often referred to as the \"manul\" or \"Pallas\\'s cat.\"'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot_output['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dai4-F3B76l",
        "outputId": "4192d678-8884-4fc4-b003-8ee7d350c375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't have personal favorites, but I can tell you that Manul cats, also known as Pallas's cats, are quite fascinating. They are small wild cats native to Central Asia, known for their round faces and long, dense fur. They are often referred to as the \"manul\" or \"Pallas's cat.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_output = chatbot(query=\"Which node has the highest betweenness centrality score? Use a k value of 10\", history=\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OPyzi4XWL_r",
        "outputId": "6c23c97e-4595-41ee-fb46-5a907dca4dec",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_NetworkX_cuGraph` with `{'query': 'Which node has the highest betweenness centrality score? Use a k value of 10'}`\n",
            "\n",
            "\n",
            "\u001b[0m1) Generating NetworkX code\n",
            "----------\n",
            "import networkx as nx\n",
            "\n",
            "# Assuming G_adb is already defined and populated\n",
            "\n",
            "# Calculate betweenness centrality for the graph\n",
            "betweenness_centrality = nx.betweenness_centrality(G_adb, k=10)\n",
            "\n",
            "# Find the node with the highest betweenness centrality score\n",
            "max_betweenness_node = max(betweenness_centrality, key=betweenness_centrality.get)\n",
            "\n",
            "FINAL_RESULT = max_betweenness_node\n",
            "----------\n",
            "\n",
            "2) Executing NetworkX code\n",
            "Attempt number 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[09:46:48 +0000] [INFO]: Graph 'Mathoverflow' load took 1.1924223899841309s\n",
            "INFO:nx_arangodb:Graph 'Mathoverflow' load took 1.1924223899841309s\n",
            "[09:46:51 +0000] [INFO]: NXCG Graph construction took 2.474351644515991s\n",
            "INFO:nx_arangodb:NXCG Graph construction took 2.474351644515991s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "FINAL_RESULT: Mathoverflow_node/7217\n",
            "----------\n",
            "3) Formulating final answer\n",
            "\u001b[33;1m\u001b[1;3mThe node with the highest betweenness centrality score is `Mathoverflow_node/7217`.\u001b[0m\u001b[32;1m\u001b[1;3m[{\"name\": \"Favorite_Pet\", \"arguments\": {\"query\": \"What is your favorite pet?\"}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Current issue: Getting images to show up in the chat"
      ],
      "metadata": {
        "id": "U95iSfSzWnAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Temp' fix for 3 million year old colab bug\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install gradio\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ghkgw26ckFjk",
        "outputId": "8487d95b-0290-4591-91f2-16f5be82c23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.19.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.19.0-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.19.0 gradio-client-1.7.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A queryfile is a zip that contains a .csv record of the query history,\n",
        "# and a folder of plot image files\n",
        "\n",
        "# Create temporary folder to store a queryfile temp folder: The folder is temp because it will get zipped later: One queryfile one zip, at a time\n",
        "!mkdir /content/queryfile_temp"
      ],
      "metadata": {
        "id": "Jn0Tv4WNdUFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# App logic\n",
        "\n",
        "QUERYFILE_FOLDER_PATH = \"/content/queryfile_temp\"\n",
        "\n",
        "process_log_list = [] # List of strings of verbose agent output (for debugging purposes, not recorded in queryfile)\n",
        "\n",
        "generated_plots_list = [] # List of paths to each plot in ../queryfile_temp/plots/\n",
        "query_history = pd.DataFrame(columns=[\"HumanMessage\", \"AIMessage\", \"GeneratedPlotPath\"])\n",
        "\n",
        "# Checks if temp file  exists, appends chat log (HumanMessage, AIMessage, GeneratedPlotPath) into a dataframe\n",
        "def queryfile_recorder(query_history, query : str, final_state_output : str, generated_plot_path : str):\n",
        "    try:\n",
        "      os.makedirs(QUERY_FOLDER_PATH, exist_ok=False)\n",
        "    except FileExistsError as e:\n",
        "      print(f\"ERROR: {e}. Temp folder already exists.\")\n",
        "      record_success = False\n",
        "    else:\n",
        "      record_success = True\n",
        "\n",
        "# We're appending empty paths to generated plots for now, until we come up with a tool that generates matplotlib plots...\n",
        "# ... that the agent can use\n",
        "    query_history.loc[len(query_history)] = [HumanMessage(content=query), AIMessage(content=final_state_output), generated_plot_path]\n",
        "\n",
        "    return record_success\n",
        "\n",
        "# Saves query_history as csv. Only call after queryfile_recorder() is called.\n",
        "def save_queryfile(query_history):\n",
        "    creation_datetime = datetime.now(timezone.utc).isoformat()\n",
        "    query_history.to_csv(QUERYFILE_FOLDER_PATH + f\"/queryfile_{creation_datetime}.csv\")\n",
        "\n",
        "def add_process_log(new_log):\n",
        "    process_log_list.append(new_log+\"\\n\")\n",
        "\n",
        "def show_process_logs():\n",
        "    process_logs_string = \"\\n\".join(process_logs_list)\n",
        "    return process_logs_string\n",
        "\n",
        "def chatbot(query: str, history):\n",
        "# Generate the output\n",
        "    if (len(query_history) == 0): # No history yet\n",
        "      final_state = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}],})\n",
        "    else:\n",
        "      final_state = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}], \"chat_history\": query_history,})\n",
        "\n",
        "    dummy = final_state[\"output\"]\n",
        "    final_state[\"text\"] = dummy # Because Gradio's ChatInterface implementation is dumb\n",
        "\n",
        "# Append empty strings for GeneratedPlotPath in queryfile_recorder(), since we havent created the agent tool to generate plots yet\n",
        "    queryfile_handler(query_history, query, final_state[\"output\"], \"\")\n",
        "\n",
        "#    add_process_log(final_state)\n",
        "\n",
        "    return final_state[\"output\"]\n"
      ],
      "metadata": {
        "id": "0tGecMzFtRko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "  with gr.Row():\n",
        "\n",
        "    with gr.Column(scale=1): # Column for charts/graph and such\n",
        "      plots_gallery = gr.Gallery(\n",
        "                   label=\"Graphs/Charts\",\n",
        "                   show_label=False,\n",
        "                   elem_id=\"gallery\",\n",
        "                   columns = [1],\n",
        "                   object_fit=\"contain\",\n",
        "                   height=\"auto\"\n",
        "                   )\n",
        "\n",
        "      with gr.Accordion(\"Process Logs\"): # For process logs\n",
        "        process_logs = gr.Textbox(value = show_process_logs(), every = 0.1, show_label = False)\n",
        "\n",
        "\n",
        "    with gr.Column(scale=5): # Column for the chatbot\n",
        "      gr.ChatInterface(fn=chatbot, type=\"messages\", title=\"AskYourGraph\", additional_outputs=None) # additional_outputs = plots_gallery once chatbot is made to handle it\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MEPTyrFckOHY",
        "outputId": "85e0be52-9566-4348-c068-6ecfe752531d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://770866b103c8c4cd05.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://770866b103c8c4cd05.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_AQL_to_Text` with `{'query': 'Return an edge where `Finefoods_node/318552` is the start node. Provide details about the edge. Who wrote the review? What is the overall sentiment of the review text?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  FILTER edge._from == 'Finefoods_node/318552'\n",
            "  RETURN {\n",
            "    edgeDetails: edge,\n",
            "    reviewer: edge.review/profileName,\n",
            "    sentiment: edge.review/text\n",
            "  }\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3mcollection or view not found: profileName\u001b[0m\n",
            "\n",
            "AQL Query (2):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  FILTER edge._from == 'Finefoods_node/318552'\n",
            "  RETURN {\n",
            "    edgeDetails: edge,\n",
            "    reviewer: edge.`review/profileName`,\n",
            "    sentiment: edge.`review/text`\n",
            "  }\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'edgeDetails': {'_key': '552183', '_id': 'Finefoods_node_to_Finefoods_node/552183', '_from': 'Finefoods_node/318552', '_to': 'Finefoods_node/329901', '_rev': '_jSWSG62--R', 'review/profileName': 'ragheed13', 'review/helpfulness': '1/1', 'review/score': '4.0', 'review/summary': 'Good Saffron!', 'review/text': \"My wife use this saffron and it gives food great taste, this brand is good quality, we like it and I it's my third order from Safinter Saffron. Their price is affordable comparing to the quality, the only reason I didn't rate 5 stars because there might be better saffron.. but more expensive of course!!\"}, 'reviewer': 'ragheed13', 'sentiment': \"My wife use this saffron and it gives food great taste, this brand is good quality, we like it and I it's my third order from Safinter Saffron. Their price is affordable comparing to the quality, the only reason I didn't rate 5 stars because there might be better saffron.. but more expensive of course!!\"}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mThe edge where `Finefoods_node/318552` is the start node has been identified. The review was written by 'ragheed13'. The overall sentiment of the review text is positive. The reviewer's wife uses the saffron and finds it to give food a great taste. The brand is considered good quality, and the reviewer likes it so much that it is their third order from Safinter Saffron. The price is deemed affordable compared to the quality, although the reviewer acknowledges that there might be better saffron available at a higher cost.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_AQL_to_Text` with `{'query': 'What is the node with the most edges?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "LET edges = (\n",
            "  FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  RETURN edge\n",
            ")\n",
            "LET nodeCounts = (\n",
            "  FOR node IN edges\n",
            "  COLLECT node._from WITH COUNT INTO length\n",
            "  RETURN { node: node._from, count: length }\n",
            ")\n",
            "RETURN nodeCounts[0]\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3msyntax error, unexpected '.', expecting assignment near '._from WITH COUNT INTO length\n",
            "  ...' at position 8:15\u001b[0m\n",
            "\n",
            "AQL Query (2):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "LET edges = (\n",
            "  FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  RETURN edge\n",
            ")\n",
            "LET nodeCounts = (\n",
            "  FOR node IN edges\n",
            "  COLLECT node._from INTO nodeCount\n",
            "  RETURN { node: nodeCount, count: LENGTH(nodeCount) }\n",
            ")\n",
            "RETURN nodeCounts[0]\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3msyntax error, unexpected '.', expecting assignment near '._from INTO nodeCount\n",
            "  RETURN {...' at position 8:15\u001b[0m\n",
            "\n",
            "AQL Query (3):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "LET edges = (\n",
            "  FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  RETURN edge\n",
            ")\n",
            "LET nodeCounts = (\n",
            "  FOR node IN edges\n",
            "  COLLECT node._from INTO nodeCount\n",
            "  RETURN { node: nodeCount, count: LENGTH(nodeCount) }\n",
            ")\n",
            "RETURN nodeCounts\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3msyntax error, unexpected '.', expecting assignment near '._from INTO nodeCount\n",
            "  RETURN {...' at position 8:15\u001b[0m\n",
            "\n",
            "AQL Query (4):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "LET edges = (\n",
            "  FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  RETURN edge\n",
            ")\n",
            "LET nodeCounts = (\n",
            "  FOR node IN edges\n",
            "  COLLECT node._from INTO nodeCount\n",
            "  RETURN { node: nodeCount, count: LENGTH(nodeCount) }\n",
            ")\n",
            "RETURN nodeCounts\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3msyntax error, unexpected '.', expecting assignment near '._from INTO nodeCount\n",
            "  RETURN {...' at position 8:15\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2096, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1641, in call_function\n",
            "    prediction = await fn(*processed_input)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 857, in async_wrapper\n",
            "    response = await f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py\", line 862, in _submit_fn\n",
            "    response = await anyio.to_thread.run_sync(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-122-5c5851159000>\", line 2, in chatbot\n",
            "    result = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}]})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1624, in _call\n",
            "    next_step_output = self._take_next_step(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in _take_next_step\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in <listcomp>\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1415, in _iter_next_step\n",
            "    yield self._perform_agent_action(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1437, in _perform_agent_action\n",
            "    observation = tool.run(\n",
            "                  ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 760, in run\n",
            "    raise error_to_raise\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 729, in run\n",
            "    response = context.run(self._run, *tool_args, **tool_kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\", line 86, in _run\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-119-4c9c5984f946>\", line 28, in text_to_aql_to_text\n",
            "    result = chain.invoke(query)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/chains/graph_qa/arangodb.py\", line 244, in _call\n",
            "    raise ValueError(m)\n",
            "ValueError: \n",
            "                Maximum amount of AQL Query Generation attempts reached.\n",
            "                Unable to execute the AQL Query due to the following error:\n",
            "                syntax error, unexpected '.', expecting assignment near '._from INTO nodeCount\n",
            "  RETURN {...' at position 8:15\n",
            "            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_NetworkX_cuGraph` with `{'query': 'What node has the most edges?'}`\n",
            "\n",
            "\n",
            "\u001b[0m1) Generating NetworkX code\n",
            "----------\n",
            "import networkx as nx\n",
            "\n",
            "# Assuming G_adb is already defined and loaded with the given schema\n",
            "\n",
            "# Step 1: Identify the nodes with the highest degree\n",
            "degree_dict = dict(G_adb.degree())\n",
            "\n",
            "# Step 2: Find the node with the maximum degree\n",
            "max_degree_node = max(degree_dict, key=degree_dict.get)\n",
            "\n",
            "# Step 3: Store the result\n",
            "FINAL_RESULT = max_degree_node\n",
            "----------\n",
            "\n",
            "2) Executing NetworkX code\n",
            "Attempt number 1\n",
            "----------\n",
            "FINAL_RESULT: Finefoods_node/327539\n",
            "----------\n",
            "3) Formulating final answer\n",
            "\u001b[33;1m\u001b[1;3mThe node with the most edges in the graph is `Finefoods_node/327539`.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_AQL_to_Text` with `{'query': \"Give 3 edges originating from the node with the most edges in the graph. If you don't recall it, it's `Finefoods_node/327539`.\"}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2096, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1641, in call_function\n",
            "    prediction = await fn(*processed_input)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 857, in async_wrapper\n",
            "    response = await f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py\", line 862, in _submit_fn\n",
            "    response = await anyio.to_thread.run_sync(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-122-5c5851159000>\", line 2, in chatbot\n",
            "    result = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}]})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1624, in _call\n",
            "    next_step_output = self._take_next_step(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in _take_next_step\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in <listcomp>\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1415, in _iter_next_step\n",
            "    yield self._perform_agent_action(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1437, in _perform_agent_action\n",
            "    observation = tool.run(\n",
            "                  ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 760, in run\n",
            "    raise error_to_raise\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 729, in run\n",
            "    response = context.run(self._run, *tool_args, **tool_kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\", line 86, in _run\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-119-4c9c5984f946>\", line 28, in text_to_aql_to_text\n",
            "    result = chain.invoke(query)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/chains/graph_qa/arangodb.py\", line 164, in _call\n",
            "    aql_generation_output = self.aql_generation_chain.run(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\", line 181, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 606, in run\n",
            "    return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\", line 181, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 860, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 690, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 925, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 547, in _generate\n",
            "    response = self.completion_with_retry(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 466, in completion_with_retry\n",
            "    rtn = _completion_with_retry(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 463, in _completion_with_retry\n",
            "    _raise_on_error(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 170, in _raise_on_error\n",
            "    raise httpx.HTTPStatusError(\n",
            "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_AQL_to_Text` with `{'query': \"Give 3 edges originating from the node with the most edges in the graph. If you don't recall it, it's Finefoods_node/327539.\"}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR vertex IN Finefoods_node\n",
            "  FILTER vertex._id == 'Finefoods_node/327539'\n",
            "  FOR edge IN 1..1 OUTBOUND vertex Finefoods_node_to_Finefoods_node\n",
            "    LIMIT 3\n",
            "    RETURN edge\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'_key': '328338', '_id': 'Finefoods_node/328338', '_rev': '_jSWRDCy-_A'}, {'_key': '328337', '_id': 'Finefoods_node/328337', '_rev': '_jSWRDCy-_-'}, {'_key': '328336', '_id': 'Finefoods_node/328336', '_rev': '_jSWRDCy--9'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mBased on the information provided, here are the three edges originating from the node with the most edges in the graph:\n",
            "\n",
            "1. Edge with key '328338' and ID 'Finefoods_node/328338'.\n",
            "2. Edge with key '328337' and ID 'Finefoods_node/328337'.\n",
            "3. Edge with key '328336' and ID 'Finefoods_node/328336'.\n",
            "\n",
            "These edges are the top three connections from the specified node.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_AQL_to_Text` with `{'query': 'Provide details about those edges. What do those reviews say and who wrote them?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  RETURN {\n",
            "    review: edge.review,\n",
            "    profileName: edge.review.profileName\n",
            "  }\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}, {'review': None, 'profileName': None}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mIt appears that the reviews and profile names are not available in the edges of the `Finefoods_node_to_Finefoods_node` collection. This could be due to missing or null data in the collection. If you have more specific details or additional collections that might contain this information, please provide them so I can assist you further.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_AQL_to_Text` with `{'query': 'Provide information about the edge with key 328338. What does the review say and who wrote this review?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  FILTER edge._key == '328338'\n",
            "  RETURN {\n",
            "    review: edge.review/text,\n",
            "    profileName: edge.review/profileName\n",
            "  }\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3mcollection or view not found: profileName\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/chains/graph_qa/arangodb.py\", line 211, in _call\n",
            "    aql_result = self.graph.query(aql_query, self.top_k)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/graphs/arangodb_graph.py\", line 117, in query\n",
            "    cursor = self.__db.aql.execute(query, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/arango/aql.py\", line 492, in execute\n",
            "    return self._execute(request, response_handler)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/arango/api.py\", line 74, in _execute\n",
            "    return self._executor.execute(request, response_handler)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/arango/executor.py\", line 67, in execute\n",
            "    return response_handler(resp)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/arango/aql.py\", line 489, in response_handler\n",
            "    raise AQLQueryExecuteError(resp, request)\n",
            "arango.exceptions.AQLQueryExecuteError: [HTTP 404][ERR 1203] collection or view not found: profileName\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2096, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1641, in call_function\n",
            "    prediction = await fn(*processed_input)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 857, in async_wrapper\n",
            "    response = await f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py\", line 862, in _submit_fn\n",
            "    response = await anyio.to_thread.run_sync(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-122-5c5851159000>\", line 2, in chatbot\n",
            "    result = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}]})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1624, in _call\n",
            "    next_step_output = self._take_next_step(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in _take_next_step\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in <listcomp>\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1415, in _iter_next_step\n",
            "    yield self._perform_agent_action(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1437, in _perform_agent_action\n",
            "    observation = tool.run(\n",
            "                  ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 760, in run\n",
            "    raise error_to_raise\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 729, in run\n",
            "    response = context.run(self._run, *tool_args, **tool_kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\", line 86, in _run\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-119-4c9c5984f946>\", line 28, in text_to_aql_to_text\n",
            "    result = chain.invoke(query)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/chains/graph_qa/arangodb.py\", line 224, in _call\n",
            "    aql_generation_output = self.aql_fix_chain.run(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\", line 181, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 606, in run\n",
            "    return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\", line 181, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 860, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 690, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 925, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 547, in _generate\n",
            "    response = self.completion_with_retry(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 466, in completion_with_retry\n",
            "    rtn = _completion_with_retry(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 463, in _completion_with_retry\n",
            "    _raise_on_error(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 170, in _raise_on_error\n",
            "    raise httpx.HTTPStatusError(\n",
            "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_AQL_to_Text` with `{'query': 'Provide information about the edge with key 328338. What does the review say and who wrote this review?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  FILTER edge._key == '328338'\n",
            "  RETURN {\n",
            "    review: edge.review/text,\n",
            "    profileName: edge.review/profileName\n",
            "  }\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3mcollection or view not found: profileName\u001b[0m\n",
            "\n",
            "AQL Query (2):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  FILTER edge._key == '328338'\n",
            "  RETURN {\n",
            "    review: edge.review/text,\n",
            "    profileName: edge.review.profileName\n",
            "  }\n",
            "\u001b[0m\n",
            "AQL Query Execution Error: \n",
            "\u001b[33;1m\u001b[1;3mcollection or view not found: text\u001b[0m\n",
            "\n",
            "AQL Query (3):\u001b[32;1m\u001b[1;3mWITH Finefoods_node_to_Finefoods_node\n",
            "FOR edge IN Finefoods_node_to_Finefoods_node\n",
            "  FILTER edge._key == '328338'\n",
            "  RETURN {\n",
            "    review: edge['review/text'],\n",
            "    profileName: edge['review/profileName']\n",
            "  }\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'review': 'Not a big fan of milk chocolate but this is great!  I will buy again.  I have zero (0) will power.', 'profileName': 'Barbara A. Dagger \"muzzer\"'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mThe review with key 328338 was written by Barbara A. Dagger \"muzzer\". The review states: \"Not a big fan of milk chocolate but this is great! I will buy again. I have zero (0) will power.\"\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://770866b103c8c4cd05.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some tested enduser prompts:\n",
        "\"Which node has the highest betweenness centrality score? Use a k value of 10? Can you also retrieve the profileName of the node?\"\n",
        "\"Can you form an AQL query that checks for a few nodes that has Finefoods_node/596 as the start node?\""
      ],
      "metadata": {
        "id": "3ECofRneGsbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(MISTRAL_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEkQ0H8hJVAr",
        "outputId": "aeb52baa-53a7-43da-9262-75397797c55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A7K3bqlcBkmvNTXHOcA4tgZwfKczavLa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZnpjEBwXRX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3b110fd-f074-422f-9dfb-ce491a7a9c07",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7016d5542e09c35e1a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7016d5542e09c35e1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2096, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1641, in call_function\n",
            "    prediction = await fn(*processed_input)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 857, in async_wrapper\n",
            "    response = await f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py\", line 862, in _submit_fn\n",
            "    response = await anyio.to_thread.run_sync(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-32-5c5851159000>\", line 2, in chatbot\n",
            "    result = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}]})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1624, in _call\n",
            "    next_step_output = self._take_next_step(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in _take_next_step\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in <listcomp>\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1358, in _iter_next_step\n",
            "    output = self._action_agent.plan(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 581, in plan\n",
            "    for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 3409, in stream\n",
            "    yield from self.transform(iter([input]), config, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 3396, in transform\n",
            "    yield from self._transform_stream_with_config(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 2196, in _transform_stream_with_config\n",
            "    chunk: Output = context.run(next, iterator)  # type: ignore\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 3359, in _transform\n",
            "    yield from final_pipeline\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 1414, in transform\n",
            "    for ichunk in input:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 5567, in transform\n",
            "    yield from self.bound.transform(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\", line 1432, in transform\n",
            "    yield from self.stream(final, config, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 415, in stream\n",
            "    for chunk in self._stream(messages, stop=stop, **kwargs):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 597, in _stream\n",
            "    for chunk in self.completion_with_retry(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 454, in iter_sse\n",
            "    _raise_on_error(event_source.response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 170, in _raise_on_error\n",
            "    raise httpx.HTTPStatusError(\n",
            "httpx.HTTPStatusError: Error response 401 while fetching https://api.mistral.ai/v1/chat/completions: {\n",
            "  \"message\":\"Unauthorized\",\n",
            "  \"request_id\":\"f2b71f4a675f8f54814dd12b5bd8b87a\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://7016d5542e09c35e1a.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "gr.ChatInterface(fn=chatbot, type=\"messages\").launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(fn=chatbot, type=\"messages\").launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "U4kh4OpRqKub",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "727f9e8e-7756-4759-84e3-3a66894ce744",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://149fa9e9d07647569c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://149fa9e9d07647569c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Text_to_NetworkX_cuGraph` with `{'query': 'Which node has the highest betweenness centrality score? Use a k value of 10. Do not subgraph the ArangoDB graph.'}`\n",
            "\n",
            "\n",
            "\u001b[0m1) Generating NetworkX code\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2096, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1641, in call_function\n",
            "    prediction = await fn(*processed_input)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 857, in async_wrapper\n",
            "    response = await f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py\", line 862, in _submit_fn\n",
            "    response = await anyio.to_thread.run_sync(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-70-43baad001cbb>\", line 2, in chatbot\n",
            "    result = agent_executor.invoke({\"input\": [{\"role\": \"user\", \"content\": query}]})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1624, in _call\n",
            "    next_step_output = self._take_next_step(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in _take_next_step\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1330, in <listcomp>\n",
            "    [\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1415, in _iter_next_step\n",
            "    yield self._perform_agent_action(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/agents/agent.py\", line 1437, in _perform_agent_action\n",
            "    observation = tool.run(\n",
            "                  ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 754, in run\n",
            "    raise error_to_raise\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\", line 723, in run\n",
            "    response = context.run(self._run, *tool_args, **tool_kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/tools/structured.py\", line 85, in _run\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-48-a12e3c931943>\", line 39, in text_to_nx_algorithm_to_text\n",
            "    text_to_nx = llm.invoke(llm_invoke_prompt).content\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 284, in invoke\n",
            "    self.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 860, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 690, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 925, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 547, in _generate\n",
            "    response = self.completion_with_retry(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 466, in completion_with_retry\n",
            "    rtn = _completion_with_retry(**kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 463, in _completion_with_retry\n",
            "    _raise_on_error(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_mistralai/chat_models.py\", line 170, in _raise_on_error\n",
            "    raise httpx.HTTPStatusError(\n",
            "httpx.HTTPStatusError: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7867 <> https://149fa9e9d07647569c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a53890bf56742eb89a8dc5b2cca9c62": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_b84405cbc41d45b1b5339df703c17e14",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "(NX → ADB): Nodes \u001b[38;2;151;196;35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;151;196;35m╸\u001b[0m \u001b[35m100%\u001b[0m (330001/330317) \u001b[33m0:00:08\u001b[0m\n     ADB Import: 'Finefoods_node' (10000) \u001b[38;2;91;192;222m▰▰▰▱▱▱▱\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(NX → ADB): Nodes <span style=\"color: #97c423; text-decoration-color: #97c423\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> (330001/330317) <span style=\"color: #808000; text-decoration-color: #808000\">0:00:08</span>\n     ADB Import: 'Finefoods_node' (10000) <span style=\"color: #5bc0de; text-decoration-color: #5bc0de\">▰▰▰▱▱▱▱</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "b84405cbc41d45b1b5339df703c17e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615ff9a3ffb447d2a8193e5423d73d1f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a3d9c13360b34f75ad775acdbe72577e",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "(NX → ADB): Edges \u001b[38;2;94;49;8m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m (560804/560804) \u001b[33m0:01:11\u001b[0m\n     ADB Import: 'Finefoods_node_to_Finefoods_node' (803) \u001b[38;2;91;192;222m▰▱▱▱▱▱▱\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">(NX → ADB): Edges <span style=\"color: #5e3108; text-decoration-color: #5e3108\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> (560804/560804) <span style=\"color: #808000; text-decoration-color: #808000\">0:01:11</span>\n     ADB Import: 'Finefoods_node_to_Finefoods_node' (803) <span style=\"color: #5bc0de; text-decoration-color: #5bc0de\">▰▱▱▱▱▱▱</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "a3d9c13360b34f75ad775acdbe72577e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}